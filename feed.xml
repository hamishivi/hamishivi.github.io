<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://hamishivi.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://hamishivi.github.io/" rel="alternate" type="text/html" /><updated>2023-11-20T06:00:56+00:00</updated><id>https://hamishivi.github.io/feed.xml</id><title type="html">Hamish Ivison</title><subtitle>Hamish's site.</subtitle><entry><title type="html">Does GPT-3 know Ancient Greek?</title><link href="https://hamishivi.github.io/2022/09/07/gpt3-greek.html" rel="alternate" type="text/html" title="Does GPT-3 know Ancient Greek?" /><published>2022-09-07T00:00:00+00:00</published><updated>2022-09-07T00:00:00+00:00</updated><id>https://hamishivi.github.io/2022/09/07/gpt3-greek</id><content type="html" xml:base="https://hamishivi.github.io/2022/09/07/gpt3-greek.html">&lt;p&gt;I don’t know quite why, but recently I’ve been thinking about zero-shot multilingual translation, and so I decided to try to see how well GPT-3 can handle low-resource ancient languages. I have some training in Latin and Ancient Greek (technically, I have a degree in Ancient Greek), so I figured I would see how well it went with them. This is going to just be a &lt;em&gt;qualitative&lt;/em&gt; analysis, rather than me trying to build some Latin/Ancient Greek translation benchmark, to keep things light and easy. By no means is this thorough or definitive!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;14/02/23 Update&lt;/strong&gt;: I have updated the model responses in light of the recently-released ChatGPT and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text-davinci-003&lt;/code&gt; models, scroll to the bottom of this page to check them out!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;latin&quot;&gt;Latin&lt;/h2&gt;

&lt;p&gt;Latin has more text extant than Ancient Greek (I think - at least, it would be more common than Ancient Greek in some random web/book crawl). So this should mean GPT-3 is better at it. Furthermore, Google Translate Latin exists, which provides a fun comparison.&lt;/p&gt;

&lt;p&gt;Let’s take a few lines from Book 12 of the Aeneid, and see how it goes. For those who haven’t used GPT-3 before, it works by &lt;em&gt;prompting&lt;/em&gt; it with some text in natural language, and then letting it autocomplete your text (a bit like pressing autocomplete on a keyboard, but for a full paragraph). People often try out multiple prompts to work out what is best - I messed around a little and settled on a basic format of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Translate the following to English: &amp;lt;text&amp;gt; English:&lt;/code&gt;, which seemed to do okay. In the following chunks, &lt;strong&gt;bolded&lt;/strong&gt; indicates model-generated text, with the rest of the text being input by me:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Translate the following to English:&lt;/p&gt;

  &lt;p&gt;Turnus ut infractos adverso Marte Latinos defecisse videt, sua nunc promissa reposci, se signari oculis, ultro implacabilis ardet attollitque animos. Poenorum qualis in arvis saucius ille gravi venantum vulnere pectus tum demum movet arma leo gaudetque comantis excutiens cervice toros fixumque latronis inpavidus frangit telum et fremit ore cruento: haud secus adcenso gliscit violentia Turno.&lt;/p&gt;

  &lt;p&gt;English:&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Turnus sees the Latins defeated by Mars and is furious, demanding that his promises be fulfilled. He is determined to take revenge and rallies his troops. Just as a wounded lion in the fields finally moves to attack the hunters who wounded him, after shaking off the blood from his mane, and breaks the spear of the bold robber with his powerful neck, so too does Turnus’ fury grow as he climbs up to fight.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For those of you who didn’t spend your final year of high school memorising book 12 of the Aeneid, here’s a professional translation (&lt;a href=&quot;https://www.poetryintranslation.com/PITBR/Latin/VirgilAeneidXII.php#anchor_Toc6669703&quot;&gt;from poetry in translation&lt;/a&gt;):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;When Turnus saw the Latins exhausted, and weakened by their military reverse, himself the subject of every gaze, his own promise to them yet unfulfilled, he burned implacably, and unprompted, and raised his courage. As a lion, in the African bush, severely hurt by huntsmen with a wound to the chest, only then rouses himself to battle, tosses his shaggy mane over his neck, in joy, and, unafraid, snaps off the spear some poacher has planted in him, roaring from blood-stained jaws: so the violence grew in Turnus’s inflamed heart.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This does pretty well! It sort of muddles bits, but the lion simile remains intact in a nice way. By the way, Google Translate does awful here:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Turnus sees that the Latins, broken in opposition to Mars, have failed, now that their promises have been restored, and that they have been sealed with their eyes; He inflicts punishments such as those in the fields on the chest of the hunted with a severe wound, then at last he moves his arms like a lion and rejoices, shaking the neck of the commander, fixed on his neck, and fearlessly breaks his weapon and roars with a bloody mouth: just as the burning violence of Turnus glides.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So it appears (to me) that GPT-3 has a better idea of Latin than whatever Google uses! The Aeneid is too easy, though - an all-time classic, which has probably appeared all over in GPT-3’s training. Let’s try something a bit different, Ovid’s &lt;em&gt;Ars Amatoria&lt;/em&gt; (still famous, but not as mega-famous as &lt;em&gt;the&lt;/em&gt; Roman Epic). I’ll use an easier sentence:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Translate the following to English:
Atque aliqua ex illis cum regum nomina quaeret, Quae loca, qui montes, quaeve ferantur aquae, Omnia responde, nec tantum siqua rogabit; Et quae nescieris, ut bene nota refer.&lt;/p&gt;

  &lt;p&gt;English:&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;And when she asks about the names of the kings, the places, the mountains, and the waters that are mentioned, answer everything, and even if she doesn’t ask, explain what you know clearly. And if you don’t know something, say so.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here’s Google’s version:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;And when some of them ask for the names of kings, what places, what mountains, what waters are carried, answer everything, and he will not ask so much; And what you do not know, report as well known.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And a more professional, actual translation:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;And if she, among them, asks the name of a king, what place, what mountains, and what stream’s displayed, you can reply to all, and more if she asks: and what you don’t know, reply as memory prompts.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So GPT-3 did pretty well here! Although the final sentence is wrong (Ovid says to say what you can recall, rather than to say if you don’t know).&lt;/p&gt;

&lt;p&gt;For good measure, let’s try something legal (albeit still fairly straightforward): Cicero’s &lt;em&gt;Pro Roscio Amerino&lt;/em&gt;, a famous legal defence.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Translate the following to English:
fide sapientiaque vestra fretus plus oneris sustuli quam ferre me posse intellego. hoc onus si vos aliqua ex parte adlevabitis, feram ut potero studio et industria, iudices; sin a vobis, id quod non spero, deserar, tamen animo non deficiam et id quod suscepi quoad potero perferam. quod si perferre non potero1, opprimi me onere offici malo quam id quod mihi cum fide semel impositum est aut propter perfidiam abicere aut propter infirmitatem animi deponere.&lt;/p&gt;

  &lt;p&gt;English:&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;I realize that I have taken on more than I can handle, but I am relying on your wisdom and support. If you can help me in any way, I will do my best to carry on, judges. If I am abandoned by you, which I do not hope for, I will not give up and will do my best to carry out what I have started. If I cannot do so, I would rather be crushed by the weight of my responsibilities than abandon or give up on what has been entrusted to me.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A professional translation would be:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Relying on your integrity and wisdom, I have undertaken a greater burden than, I am well aware, I am able to bear. If you, in some degree, lighten this burden, O judges, I will bear it as well as I can with zeal and industry. But if, as I do not expect, I am abandoned by you, still I will not fail in courage, and I will bear what I have undertaken as well as I can. But if I cannot support it, I had rather be overwhelmed by the weight of my duty, than either through treachery betray, or through weakness of mind desert, that which has been once honestly entrusted to me.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As a final fun test, let’s see if GPT-3 knows the basic forms of the verb to be:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;What is the 1st person singular form of the verb ‘to be’ in Latin?
&lt;strong&gt;Sum&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;What is the 2nd person singular form of the verb ‘to be’ in Latin?
&lt;strong&gt;The 2nd person singular form of the verb ‘to be’ in Latin is ‘est’.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;What is the 3rd person singular form of the verb ‘to be’ in Latin?
&lt;strong&gt;The third person singular form of the verb “to be” in Latin is “est.”&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;What is the 1st person plural form of the verb ‘to be’ in Latin?
&lt;strong&gt;sumus&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;What is the 2nd person plural form of the verb ‘to be’ in Latin?
&lt;strong&gt;You are (plural)&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;What is the 3rd person plural form of the verb ‘to be’ in Latin?
&lt;strong&gt;Sunt.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Well, it gets a bit confused, although I think this is quite hard considering the prompt doesn’t give any examples. I find it interesting it gets the 2nd person forms wrong, considering those are forms I have found to be far far less common than the others.&lt;/p&gt;

&lt;p&gt;This did a really good job! Overall, I’m really impressed by GPT-3’s Latin abilities. I wouldn’t put it past it having memorised these texts (these all exist on the internet with translations usually somewhere in the same document), but it’s still quite impressive to see. It also handily beats Google, which is fun.&lt;/p&gt;

&lt;h2 id=&quot;ancient-greek&quot;&gt;Ancient Greek&lt;/h2&gt;

&lt;p&gt;Let’s start with something really easy: the first four lines of the &lt;em&gt;Iliad&lt;/em&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Translate the following to English:&lt;/p&gt;

  &lt;p&gt;μῆνιν ἄειδε θεὰ Πηληϊάδεω Ἀχιλῆος οὐλομένην, ἣ μυρί᾽ Ἀχαιοῖς ἄλγε᾽ ἔθηκε, πολλὰς δ᾽ ἰφθίμους ψυχὰς Ἄϊδι προΐαψεν ἡρώων, αὐτοὺς δὲ ἑλώρια τεῦχε κύνεσσιν οἰωνοῖσί τε πᾶσι, Διὸς δ᾽ ἐτελείετο βουλή, ἐξ οὗ δὴ τὰ πρῶτα διαστήτην ἐρίσαντε  Ἀτρεΐδης τε ἄναξ ἀνδρῶν καὶ δῖος Ἀχιλλεύς.&lt;/p&gt;

  &lt;p&gt;English:
&lt;strong&gt;Achilles, the son of Peleus, killed Hector, who had caused great harm to the Achaeans. He also killed many other brave men, and he terrified those who were still alive. This was the will of Zeus, who had first stirred up the conflict between King Atreus’ son Agamemnon and noble Achilles.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is already worse - Hector doesn’t even appear in the Greek text! However, overall it’s okay, seemingly getting a sense of the text, although being definitely incorrect at times (unlike the Latin translations, which tended to be correct). For those of you who don’t know the Iliad by heart, these lines would be translated something like (from &lt;a href=&quot;https://www.poetryintranslation.com/PITBR/Greek/Iliad1.php&quot;&gt;poetry in translation&lt;/a&gt;):&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Goddess, sing me the anger, of Achilles, Peleus’ son,
that fatal anger that brought countless sorrows on the Greeks,
and sent many valiant souls of warriors down to Hades,
leaving their bodies as spoil for dogs and
carrion birds: for thus was the will of Zeus brought to fulfilment.
Sing of it from the moment when Agamemnon, Atreus’ son, that king of men, 
parted in wrath from noble Achilles.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If you prompt it with the first clause(s), it gets a much better translation, likely due to it having encountered the beginning of the Iliad countless times in training:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Sing, Muse, of the wrath of Achilles, son of Peleus, &lt;strong&gt;that brought countless ills upon the Achaeans. Many a brave soul did it send hurrying down to Hades, and many a hero did it yield a prey to dogs and vultures, for so was the will of Zeus fulfilled from the time when first they quarreled,Atreus’ son, king of men, and brilliant Achilles.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;There are many reasons GPT-3 could doing worse for Greek, but one large change from Latin is the use of a different script. Let’s try normalising the text into beta code (a standard conversion for Ancient Greek into ASCII) and see how it goes:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Translate the following to English:&lt;/p&gt;

  &lt;p&gt;mh=nin a)/eide qea\ *phlhi+a/dew *)axilh=os ou)lome/nhn, h(\ muri/’ *)axaioi=s a)/lge’ e)/qhke, polla\s d’ i)fqi/mous yuxa\s *)/ai+di proi/+ayen h(rw/wn, au)tou\s de\ e(lw/ria teu=xe ku/nessin oi)wnoi=si/ te pa=si, *dio\s d’ e)telei/eto boulh/, e)c ou(= dh\ ta\ prw=ta diasth/thn e)ri/sante  *)atrei/+dhs te a)/nac a)ndrw=n kai\ di=os *)axilleu/s.&lt;/p&gt;

  &lt;p&gt;English:&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;After he had seen the many wrongs that had been done to Axylus, a just man, Hercules went to the land of the Achaeans and killed many of the evil men there. But he spared the life of Axylus, because he was a good man. So Zeus gave him a city and made him a god, and the first temple to Hercules was built by the men of Troy after they had been saved from disaster by Hercules and by Zeus himself.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is even worse! Removing the accent symbols (leaving only the letters) also doesn’t help. Evidently, GPT-3 doesn’t really know Ancient Greek at all (although it has definitely seen the Iliad).&lt;/p&gt;

&lt;p&gt;Since the Iliad is so famous, let’s try something more obscure. Here’s a paragraph from Heron’s &lt;em&gt;On Automata&lt;/em&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Translate the following to English:&lt;/p&gt;

  &lt;p&gt;καθὰ δὲ προεθέμην, ἐρῶ περὶ ἑνὸς πίνακος τοῦ δοκοῦντός μοι κρείττονος. μῦθος μὲν ἦν τεταγμένος ἐν αὐτῷ ὁ κατὰ τὸν Ναύπλιον. τὰ δὲ κατὰ μέρος εἶχεν οὕτως· ἀνοιχθέντος ἐν ἀρχῇ τοῦ πίνακος ἐφαίνετο ζῴδια γεγραμμένα δώδεκα· ταῦτα δὲ ἦν εἰς τρεῖς στίχους διῃρημένα· ἦσαν δὲ οὗτοι πεποιημένοι τῶν Δαναῶν τινες ἐπισκευάζοντες τὰς ναῦς καὶ γινόμενοι περὶ καθολκήν.&lt;/p&gt;

  &lt;p&gt;English:
&lt;strong&gt;I was once thinking about a picture that seemed better to me than it actually was. The subject of the picture was the story of the Odyssey. Part of the picture showed the twelve Labors of Hercules, which were divided into three groups. These were done by some of the Danaids who were repairing their ships and were becoming burdened.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And if I prompt the model with the first few words:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;…English:
As I laid out before, &lt;strong&gt;I was speaking about a painting that seemed better to me. The painting was hung in such a way that in the beginning, when you opened it, you saw twelve animals painted on it, divided into three verses. These were some of the Danaans, who, when they were repairing their ships, became encircled.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here’s the correct translation:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;As I laid out before, I will talk about one box that seems superior to me. The story set in it was the one about Naupilius. And its parts went like this. In the beginning, when the box opened, 12 painted figurines appeared. These were divided into 3 rows; and these were made to represent some of the Danaans (Greeks) preparing their ships and launching them.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So, the model has clearly learnt some vocab - it gets the number 12, it works out Danaans, ships, and a few other things. These translations seem vaguely familiar but ultimately are definitely incorrect. It’s cool that it works this well, but future classics scholars are definitely not going to be able to use it to cheat on their university homework 😜&lt;/p&gt;

&lt;h2 id=&quot;wrapping-this-up&quot;&gt;Wrapping this up&lt;/h2&gt;

&lt;p&gt;Unsurprisingly, GPT-3 is pretty good! Its Latin translation abilities seem pretty good, and it definitely feels like it has seen ancient texts written in English enough to regurgitate them when prompted. Its success at Latin makes its harsher failures in translating Ancient Greek a little surprising, but I suspect the big switch into a different script makes things much harder, and that there is simply far less Ancient Greek text in its pretraining corpus. I’ve focussed on languages I’m personally familiar with here, but it would also be interesting to see if one could somehow get a large language model like GPT-3 to give its best guess on how to translate Linear A or similar!&lt;/p&gt;

&lt;p&gt;As a technical note, I used &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text-davinci-002&lt;/code&gt; for this post.&lt;/p&gt;

&lt;h2 id=&quot;gpt35-and-chatgpt-update&quot;&gt;GPT3.5 and ChatGPT Update!&lt;/h2&gt;

&lt;p&gt;Very shortly after writing this blog post, OpenAI came out with ChatGPT and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text-davinci-003&lt;/code&gt;. Here’s a quick try of all the above prompts with these two models.&lt;/p&gt;

&lt;h3 id=&quot;text-davinci-003&quot;&gt;Text-Davinci-003&lt;/h3&gt;

&lt;p&gt;First, let’s try out &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text-davinci-003&lt;/code&gt;, the successor to text-davinci-002 (based on name and &lt;a href=&quot;https://platform.openai.com/docs/model-index-for-researchers&quot;&gt;OpenAI’s model documentation&lt;/a&gt;). I also tweaked the input prompts to indicate the original language of the text - I found this slightly improved model’s responses, especially for Greek.&lt;/p&gt;

&lt;h3 id=&quot;text-davinvi-003-latin&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text-davinvi-003&lt;/code&gt; Latin&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Translate the following to English from Latin:&lt;/p&gt;

  &lt;p&gt;Turnus ut infractos adverso Marte Latinos defecisse videt, sua nunc promissa reposci, se signari oculis, ultro implacabilis ardet attollitque animos. Poenorum qualis in arvis saucius ille gravi venantum vulnere pectus tum demum movet arma leo gaudetque comantis excutiens cervice toros fixumque latronis inpavidus frangit telum et fremit ore cruento: haud secus adcenso gliscit violentia Turno.&lt;/p&gt;

  &lt;p&gt;English:&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Turnus sees that the Latins have been defeated by the adverse forces of Mars, and he now demands his promised reward; his eyes blaze with implacable rage and his spirit is raised. Just as a wounded lion in the fields, wounded by the heavy weapons of the hunters, finally stirs and rises up, shaking his maned neck and with fearless strength breaking the spear of the robber and roaring with bloody mouth, so too does Turnus surge with violence.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Translate the following to English from Latin:&lt;/p&gt;

  &lt;p&gt;Atque aliqua ex illis cum regum nomina quaeret, Quae loca, qui montes, quaeve ferantur aquae, Omnia responde, nec tantum siqua rogabit; Et quae nescieris, ut bene nota refer.&lt;/p&gt;

  &lt;p&gt;English:&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;And when someone asks you for the names of the kings, the places they lived, the mountains, and the rivers they are said to have, answer them all, even if you are not asked; and if you don’t know something, make sure to report it back as if you did.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Translate the following to English from Latin:&lt;/p&gt;

  &lt;p&gt;fide sapientiaque vestra fretus plus oneris sustuli quam ferre me posse intellego. hoc onus si vos aliqua ex parte adlevabitis, feram ut potero studio et industria, iudices; sin a vobis, id quod non spero, deserar, tamen animo non deficiam et id quod suscepi quoad potero perferam. quod si perferre non potero1, opprimi me onere offici malo quam id quod mihi cum fide semel impositum est aut propter perfidiam abicere aut propter infirmitatem animi deponere.&lt;/p&gt;

  &lt;p&gt;English:&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Trusting in your fidelity and wisdom, I have taken on more of a burden than I understand I can bear. If you lighten this burden in any way, I shall bear it as best I can with diligence and hard work, judges; if I am abandoned by you, which I do not hope, nevertheless I shall not fail in spirit and I shall carry out as best I can what I have taken on. But if I cannot carry it out, I would rather be overwhelmed by the burden of this duty than abandon or lay down what has been entrusted to me with faithfulness because of my lack of courage.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;What is the 1st person singular form of the verb ‘to be’ in Latin?
&lt;strong&gt;Esse.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;What is the 2nd person singular form of the verb ‘to be’ in Latin?
&lt;strong&gt;Esse.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;What is the 3rd person singular form of the verb ‘to be’ in Latin?
&lt;strong&gt;Est.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;What is the 1st person plural form of the verb ‘to be’ in Latin?
&lt;strong&gt;Sumus.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;What is the 2nd person plural form of the verb ‘to be’ in Latin?
&lt;strong&gt;Estis.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;What is the 3rd person plural form of the verb ‘to be’ in Latin?
&lt;strong&gt;Sunt.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Verdict&lt;/strong&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text-davinci-003&lt;/code&gt; does really well! I think overall these translations are pretty good. You can probably quibble with some of the choices, but this is generally pretty good. However, it does get some of the basic verb form questions wrong, which is surprising - these should be really easy for it!&lt;/p&gt;

&lt;h3 id=&quot;text-davinvi-003-greek&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text-davinvi-003&lt;/code&gt; Greek&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Translate the following to English from Homeric Greek:&lt;/p&gt;

  &lt;p&gt;μῆνιν ἄειδε θεὰ Πηληϊάδεω Ἀχιλῆος οὐλομένην, ἣ μυρί᾽ Ἀχαιοῖς ἄλγε᾽ ἔθηκε, πολλὰς δ᾽ ἰφθίμους ψυχὰς Ἄϊδι προΐαψεν ἡρώων, αὐτοὺς δὲ ἑλώρια τεῦχε κύνεσσιν οἰωνοῖσί τε πᾶσι, Διὸς δ᾽ ἐτελείετο βουλή, ἐξ οὗ δὴ τὰ πρῶτα διαστήτην ἐρίσαντε  Ἀτρεΐδης τε ἄναξ ἀνδρῶν καὶ δῖος Ἀχιλλεύς.&lt;/p&gt;

  &lt;p&gt;English:
&lt;strong&gt;Sing, goddess, the anger of Peleus’ son Achilleus, that destructive wrath which brought countless woes upon the Achaeans, and sent forth to Hades many valiant souls of heroes; and made their bodies a prey for dogs and all birds, and the will of Zeus was accomplished since that time when first there stood in strife Atreus’ son, king of men, and brilliant Achilleus.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Translate the following to English from Ancient Greek:&lt;/p&gt;

  &lt;p&gt;καθὰ δὲ προεθέμην, ἐρῶ περὶ ἑνὸς πίνακος τοῦ δοκοῦντός μοι κρείττονος. μῦθος μὲν ἦν τεταγμένος ἐν αὐτῷ ὁ κατὰ τὸν Ναύπλιον. τὰ δὲ κατὰ μέρος εἶχεν οὕτως· ἀνοιχθέντος ἐν ἀρχῇ τοῦ πίνακος ἐφαίνετο ζῴδια γεγραμμένα δώδεκα· ταῦτα δὲ ἦν εἰς τρεῖς στίχους διῃρημένα· ἦσαν δὲ οὗτοι πεποιημένοι τῶν Δαναῶν τινες ἐπισκευάζοντες τὰς ναῦς καὶ γινόμενοι περὶ καθολκήν.&lt;/p&gt;

  &lt;p&gt;English: 
&lt;strong&gt;As I had previously planned, I saw a painting which seemed better to me. A myth was depicted in it, concerning the story of Nauplius. In parts, it was arranged in this way: when the painting was opened, there were twelve zodiacs written in three verses; these were composed by some of the Danaans, who were making repairs to the ships and becoming involved in a voyage.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Translate the following to English from Ancient Greek:&lt;/p&gt;

  &lt;p&gt;καθὰ δὲ προεθέμην, ἐρῶ περὶ ἑνὸς πίνακος τοῦ δοκοῦντός μοι κρείττονος. μῦθος μὲν ἦν τεταγμένος ἐν αὐτῷ ὁ κατὰ τὸν Ναύπλιον. τὰ δὲ κατὰ μέρος εἶχεν οὕτως· ἀνοιχθέντος ἐν ἀρχῇ τοῦ πίνακος ἐφαίνετο ζῴδια γεγραμμένα δώδεκα· ταῦτα δὲ ἦν εἰς τρεῖς στίχους διῃρημένα· ἦσαν δὲ οὗτοι πεποιημένοι τῶν Δαναῶν τινες ἐπισκευάζοντες τὰς ναῦς καὶ γινόμενοι περὶ καθολκήν.&lt;/p&gt;

  &lt;p&gt;English: 
As I laid out before, &lt;strong&gt;I saw a painting that seemed better than the others. There was a myth drawn on it, according to the story of Nauplius. The painting was divided into twelve parts, which were further divided into three verses. These verses were composed by some of the Greeks who were repairing their ships and preparing for a voyage.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Verdict&lt;/strong&gt;: I think that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text-davinci-003&lt;/code&gt; does much better than &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;002&lt;/code&gt; here: it gets the Iliad more or less fine, while the Heron has some issues (likely due to vocab issues). This is pretty surprisingly good to me, and I imagine with even a little exposure to more Ancient Greek text the model would do even better. Without telling it to translate ‘from Greek’, as I did for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;002&lt;/code&gt;, the model does a bit worse, and muddles more words, but is still pretty good.&lt;/p&gt;

&lt;h3 id=&quot;chatgpt&quot;&gt;ChatGPT&lt;/h3&gt;

&lt;p&gt;Next, let’s try ChatGPT. To be fair, I’m going to use the same prompts as above on a blank conversation (as there is no API available yet). To be exact, I’m using the &lt;em&gt;January 30th&lt;/em&gt; edition of ChatGPT.&lt;/p&gt;

&lt;p&gt;ChatGPT (currently) gives titles to the conversations that occur. I don’t know what model does this, but it gives some interesting insight as to what a (I guess GPT-based) model thinks is going on. I’ve included these titles below the prompt and model response.&lt;/p&gt;

&lt;h3 id=&quot;chatgpt-latin&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ChatGPT&lt;/code&gt; Latin&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Translate the following to English from Latin:&lt;/p&gt;

  &lt;p&gt;Turnus ut infractos adverso Marte Latinos defecisse videt, sua nunc promissa reposci, se signari oculis, ultro implacabilis ardet attollitque animos. Poenorum qualis in arvis saucius ille gravi venantum vulnere pectus tum demum movet arma leo gaudetque comantis excutiens cervice toros fixumque latronis inpavidus frangit telum et fremit ore cruento: haud secus adcenso gliscit violentia Turno.&lt;/p&gt;

  &lt;p&gt;English:&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;When Turnus sees that the Latins have fallen under the unfavorable power of Mars despite their unbroken spirit, he now demands that his promises be fulfilled. He rages and raises his spirit, burning with implacable anger. Just as a wounded lion in the fields, once struck by a serious wound from hunters, then only moves to arms, rejoicing as he shakes his mane and fearlessly breaks the weapon of the thief with his steadfast neck and snarling with bloody mouth, so does Turnus’s violence boil up when he ascends.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ChatGPT Title: Turnus’ Furious Ascension&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Translate the following to English from Latin:
Atque aliqua ex illis cum regum nomina quaeret, Quae loca, qui montes, quaeve ferantur aquae, Omnia responde, nec tantum siqua rogabit; Et quae nescieris, ut bene nota refer.&lt;/p&gt;

  &lt;p&gt;English:&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;And answer some of them when they ask about the names of kings, what places, what mountains, and what waters are said to exist; respond to everything, not only if someone asks; and what you do not know, report as well known.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ChatGPT Title: Answer Regal Questions&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Translate the following to English from Latin:
fide sapientiaque vestra fretus plus oneris sustuli quam ferre me posse intellego. hoc onus si vos aliqua ex parte adlevabitis, feram ut potero studio et industria, iudices; sin a vobis, id quod non spero, deserar, tamen animo non deficiam et id quod suscepi quoad potero perferam. quod si perferre non potero1, opprimi me onere offici malo quam id quod mihi cum fide semel impositum est aut propter perfidiam abicere aut propter infirmitatem animi deponere.&lt;/p&gt;

  &lt;p&gt;English:&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Relying on your faith and wisdom, I have taken on more weight than I understand I am able to bear. If you can relieve this burden in any way, I will bear it to the best of my abilities with effort and determination, judges. If I am abandoned by you, which I do not hope for, I will not let my spirit falter, and I will carry out what I have undertaken as best as I can. If I am unable to carry it out, I would rather be crushed by the weight of my duty than abandon or lay down what was once entrusted to me with faith because of my own faithlessness or weakness of spirit.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ChatGPT Title: Fide Sapientiaque Onus Sustuli&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;What is the 1st person singular form of the verb ‘to be’ in Latin?
&lt;strong&gt;In Latin, the 1st person singular form of the verb “to be” is “sum.”&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ChatGPT Title: 1st Person Singular “to be” in Latin&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;What is the 2nd person singular form of the verb ‘to be’ in Latin?
&lt;strong&gt;The 2nd person singular form of the verb “to be” in Latin is “es.”&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ChatGPT Title: 2nd Person “Es” Latin “To Be”&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;What is the 3rd person singular form of the verb ‘to be’ in Latin?
&lt;strong&gt;In Latin, the 3rd person singular form of the verb “to be” is “est”.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ChatGPT Title: 3rd Person Singular Latin “Est”&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;What is the 1st person plural form of the verb ‘to be’ in Latin?
&lt;strong&gt;The 1st person plural form of the verb “to be” in Latin is “sumus.”&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ChatGPT Title: Latin 1st Person Plural To Be&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;What is the 2nd person plural form of the verb ‘to be’ in Latin?
&lt;strong&gt;The 2nd person plural form of the verb “to be” in Latin is “estis.”&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ChatGPT Title: Latin 2nd Plural “to be”&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;What is the 3rd person plural form of the verb ‘to be’ in Latin?
&lt;strong&gt;The third person plural form of the verb “to be” in Latin is “sunt.”&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ChatGPT Title: Latin 3rd Person Plural “sunt”&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Verdict&lt;/strong&gt;: Wildly, I think ChatGPT’s quality here is still really good, and it gets all the verb forms right! I think it’s definitely as good as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text-davinci-003&lt;/code&gt;, although still a little muddled. I suspect more context would help in some cases, giving the model a better idea of what it is translating. Considering the improvements over &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;002&lt;/code&gt;, I definitely wonder if both &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text-davinci-003&lt;/code&gt; and ChatGPT have benefited from Latin students using it to help with homework… 🤔&lt;/p&gt;

&lt;h3 id=&quot;chatgpt-greek&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ChatGPT&lt;/code&gt; Greek&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Translate the following to English from Homeric Greek:&lt;/p&gt;

  &lt;p&gt;μῆνιν ἄειδε θεὰ Πηληϊάδεω Ἀχιλῆος οὐλομένην, ἣ μυρί᾽ Ἀχαιοῖς ἄλγε᾽ ἔθηκε, πολλὰς δ᾽ ἰφθίμους ψυχὰς Ἄϊδι προΐαψεν ἡρώων, αὐτοὺς δὲ ἑλώρια τεῦχε κύνεσσιν οἰωνοῖσί τε πᾶσι, Διὸς δ᾽ ἐτελείετο βουλή, ἐξ οὗ δὴ τὰ πρῶτα διαστήτην ἐρίσαντε  Ἀτρεΐδης τε ἄναξ ἀνδρῶν καὶ δῖος Ἀχιλλεύς.&lt;/p&gt;

  &lt;p&gt;English:
&lt;strong&gt;“Sing, goddess, the anger of Achilles, son of Peleus, that brought countless woes upon the Achaeans, and sent many valiant souls of heroes to Hades, and made them themselves food for dogs and all birds; for so was the will of Zeus fulfilled, from which the first sufferings arose, that of Atreus’ son, king of men, and Achilles, the glorious.”&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ChatGPT Title: Homeric Greek Translation&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Translate the following to English from Ancient Greek:&lt;/p&gt;

  &lt;p&gt;καθὰ δὲ προεθέμην, ἐρῶ περὶ ἑνὸς πίνακος τοῦ δοκοῦντός μοι κρείττονος. μῦθος μὲν ἦν τεταγμένος ἐν αὐτῷ ὁ κατὰ τὸν Ναύπλιον. τὰ δὲ κατὰ μέρος εἶχεν οὕτως· ἀνοιχθέντος ἐν ἀρχῇ τοῦ πίνακος ἐφαίνετο ζῴδια γεγραμμένα δώδεκα· ταῦτα δὲ ἦν εἰς τρεῖς στίχους διῃρημένα· ἦσαν δὲ οὗτοι πεποιημένοι τῶν Δαναῶν τινες ἐπισκευάζοντες τὰς ναῦς καὶ γινόμενοι περὶ καθολκήν.&lt;/p&gt;

  &lt;p&gt;English: 
&lt;strong&gt;“And as I previously mentioned, I love a picture that seems to me to be better. A story was depicted in it about the Naulpian. The parts were arranged in this way: when the picture was opened at the beginning, twelve zodiacs appeared written; these were divided into three lines. And these were made by some of the Danai, repairing the ships and becoming around the harbor.”&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ChatGPT Title: Description of a Superior Painting Depicting the Battle of Nafplion&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Translate the following to English:&lt;/p&gt;

  &lt;p&gt;καθὰ δὲ προεθέμην, ἐρῶ περὶ ἑνὸς πίνακος τοῦ δοκοῦντός μοι κρείττονος. μῦθος μὲν ἦν τεταγμένος ἐν αὐτῷ ὁ κατὰ τὸν Ναύπλιον. τὰ δὲ κατὰ μέρος εἶχεν οὕτως· ἀνοιχθέντος ἐν ἀρχῇ τοῦ πίνακος ἐφαίνετο ζῴδια γεγραμμένα δώδεκα· ταῦτα δὲ ἦν εἰς τρεῖς στίχους διῃρημένα· ἦσαν δὲ οὗτοι πεποιημένοι τῶν Δαναῶν τινες ἐπισκευάζοντες τὰς ναῦς καὶ γινόμενοι περὶ καθολκήν.&lt;/p&gt;

  &lt;p&gt;English: 
As I laid out before, &lt;strong&gt;I fell in love with a painting that seemed to me to be superior. There was a story depicted on it, about Nauplius. Part of it was as follows: when the painting was opened at the beginning, there were twelve zodiac signs written in it, which were divided into three lines. These were made by some of the Danaans as they were repairing their ships and undergoing hardship.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ChatGPT Title: Painted Nauplian Mythology&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Verdict&lt;/strong&gt;: Interestingly, I feel that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text-davinci-003&lt;/code&gt; did a bit better with these, and ChatGPT makes some interesting spelling errors at times (Danai? Naulpian?). Overall, it’s definitely still impressive, but I wonder if the use of (allegedly) a smaller model or the further training that ChatGPT went through has cost it some Greek ability compared to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text-davinci-003&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Overall, these model improvements are very impressive, especially considering translating Ancient Greek and Latin are likely pretty obscure uses for these models - it’d be interesting to learn if these improvements have come from explicit related feedback during the RLHF training process (students, professors giving feedback on classical language translations), or if it’s a byproduct of other tasks (e.g., feedback on general translation tasks, or further pretraining on related data). A big issue that pops out to me here is managing context: many of the issues with the Heron translation likely come from not knowing the surrounding context of the extract and choosing sub-optimal translations (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ζῴδια&lt;/code&gt; could be Zodiac-related, but it can also mean `figurine’, which is the correct translation here) from this. Likely, giving the model longer extracts or prompting it with the domain / theme / etc of the text would further improve its translations.&lt;/p&gt;

&lt;p&gt;However, even just as-is I think that the current abilities displayed here are pretty impressive, and are more than good enough to be moderately useful, although would not replace an expert translation and / or well-annotated text.&lt;/p&gt;</content><author><name></name></author><category term="blog" /><category term="non-technical" /><category term="technical" /><summary type="html">I don’t know quite why, but recently I’ve been thinking about zero-shot multilingual translation, and so I decided to try to see how well GPT-3 can handle low-resource ancient languages. I have some training in Latin and Ancient Greek (technically, I have a degree in Ancient Greek), so I figured I would see how well it went with them. This is going to just be a qualitative analysis, rather than me trying to build some Latin/Ancient Greek translation benchmark, to keep things light and easy. By no means is this thorough or definitive!</summary></entry><entry><title type="html">Blog Redesign</title><link href="https://hamishivi.github.io/2021/08/22/blog-redesign.html" rel="alternate" type="text/html" title="Blog Redesign" /><published>2021-08-22T00:00:00+00:00</published><updated>2021-08-22T00:00:00+00:00</updated><id>https://hamishivi.github.io/2021/08/22/blog-redesign</id><content type="html" xml:base="https://hamishivi.github.io/2021/08/22/blog-redesign.html">&lt;p&gt;As a quick note, I’ve recently done a go-over of the design of my blog. In this post, I’m just going to go over the changes and how my blog setup currently works. I won’t go too deep into details as my setup largely follows the standard &lt;a href=&quot;https://pages.github.com/&quot;&gt;Github Pages&lt;/a&gt; and &lt;a href=&quot;https://jekyllrb.com/&quot;&gt;Jekyll&lt;/a&gt; setup.&lt;/p&gt;

&lt;p&gt;I’m using the default &lt;a href=&quot;https://github.com/jekyll/minima&quot;&gt;Minima&lt;/a&gt; theme, considering it’s both simple and fairly easy to modify. These are currently the various things I’ve added to it (beyond general style tweaks):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A light-dark mode toggle, utilising Google Chrome Lab’s &lt;a href=&quot;https://github.com/GoogleChromeLabs/dark-mode-toggle&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dark-mode-toggle&lt;/code&gt;&lt;/a&gt; element&lt;/li&gt;
  &lt;li&gt;A tag system, based on &lt;a href=&quot;http://longqian.me/2017/02/09/github-jekyll-tag/&quot;&gt;Long Qian’s guide&lt;/a&gt;, which I also use to split my posts into the ‘side projects’ and ‘random’ sections above.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As I tweak the plugins and design, I’ll come back to this post and add my changes to the list above. Hopefully, it provides a useful list of ways to tweak a Github Pages site to your liking (and remind me of what I added if I chose to change it up again). Alternatively, you can find the codebase for this site &lt;a href=&quot;https://github.com/hamishivi/hamishivi.github.io&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><category term="blog" /><category term="non-technical" /><category term="technical" /><summary type="html">As a quick note, I’ve recently done a go-over of the design of my blog. In this post, I’m just going to go over the changes and how my blog setup currently works. I won’t go too deep into details as my setup largely follows the standard Github Pages and Jekyll setup.</summary></entry><entry><title type="html">AI-ce Attorney</title><link href="https://hamishivi.github.io/2021/08/18/aice-attorney.html" rel="alternate" type="text/html" title="AI-ce Attorney" /><published>2021-08-18T00:00:00+00:00</published><updated>2021-08-18T00:00:00+00:00</updated><id>https://hamishivi.github.io/2021/08/18/aice-attorney</id><content type="html" xml:base="https://hamishivi.github.io/2021/08/18/aice-attorney.html">&lt;blockquote&gt;
  &lt;p&gt;tl;dr: &lt;a href=&quot;https://share.streamlit.io/hamishivi/aice-attorney&quot;&gt;check out a fun little Ace Attorney generator I made!&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Ace_Attorney&quot;&gt;Phoenix Wright: Ace Attorney&lt;/a&gt;&lt;/em&gt; is a visual novel series created by Shu Takumi (also of &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Ghost_Trick:_Phantom_Detective&quot;&gt;Ghost Trick&lt;/a&gt;&lt;/em&gt; fame) where you play as a lawyer (usually the titular character Phoenix Wright, although this changes over the games) in a heavily fictionalised version of the Japanese legal system. I heavily recommend this series if you like murder mysteries or puzzle games - the gameplay loop is centred around investigating murders and finding evidence, and then using that evidence in court to prove contradictions or lies in witness’ testimonies.&lt;/p&gt;

&lt;p&gt;As a visual novel, &lt;em&gt;Ace Attorney&lt;/em&gt; is a text-heavy game, and so with the recent release of the &lt;em&gt;&lt;a href=&quot;https://www.ace-attorney.com/great1-2/en-asia/&quot;&gt;Great Ace Attorney Chronicles&lt;/a&gt;&lt;/em&gt; and the popularity of the &lt;a href=&quot;https://twitter.com/acecourtbot2?lang=en&quot;&gt;twitter court bot&lt;/a&gt;, I thought it would be fun to make use of the court bot’s code to auto-generate &lt;em&gt;Ace Attorney&lt;/em&gt; scripts and animate them! This is fairly easy to do, as it turns out - I used the great &lt;a href=&quot;https://docs.aitextgen.io/&quot;&gt;aitextgen&lt;/a&gt; library for training models and generating text, and the &lt;a href=&quot;https://github.com/LuisMayo/objection_engine&quot;&gt;objection engine library&lt;/a&gt; for animating the scripts - all I had to do really was train the model itself and write some code to convert it to a format the objection engine recognises.&lt;/p&gt;

&lt;p&gt;I made this into a little &lt;a href=&quot;https://streamlit.io/&quot;&gt;streamlit&lt;/a&gt; app available &lt;a href=&quot;https://share.streamlit.io/hamishivi/aice-attorney&quot;&gt;here&lt;/a&gt; using the &lt;a href=&quot;https://huggingface.co/EleutherAI/gpt-neo-125M&quot;&gt;125M GPT-neo&lt;/a&gt; model (in order to keep processing times reasonably fast), so check it out! And if you find yourself enjoying the scenarios, I definitely recommend checking out any of the &lt;em&gt;Ace Attorney&lt;/em&gt; games.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;🚨 It’s important to note that I’m not filtering the bot, so it could produce potentially harmful text. &lt;em&gt;Ace Attorney&lt;/em&gt; is mostly a teen-rated game, so there shouldn’t be much worse than murder mystery discussions, but the original training data of GPT-neo was much wider and expansive, so be warned!&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><category term="blog" /><category term="technical" /><summary type="html">tl;dr: check out a fun little Ace Attorney generator I made!</summary></entry><entry><title type="html">Hero’s On Automata</title><link href="https://hamishivi.github.io/2021/08/02/heron.html" rel="alternate" type="text/html" title="Hero’s On Automata" /><published>2021-08-02T00:00:00+00:00</published><updated>2021-08-02T00:00:00+00:00</updated><id>https://hamishivi.github.io/2021/08/02/heron</id><content type="html" xml:base="https://hamishivi.github.io/2021/08/02/heron.html">&lt;p&gt;Hero (or Heron) of Alexandria was a famous ancient inventor, who lived around the first century AD (i.e. early Roman empire). As you might already know from the numerous blogs and articles about him on the internet, he invented a bunch of fairly interesting mechanisms - an &lt;a href=&quot;https://en.wikipedia.org/wiki/Aeolipile&quot;&gt;early toy steam engine&lt;/a&gt; (widely regarded as the first steam engine), self-moving theatres, the first vending machine (to dispense holy water), and &lt;a href=&quot;https://www.youtube.com/watch?v=xyQIo9iS_z0&quot;&gt;arguably an early programmable cart&lt;/a&gt; (programmable via placing pegs on an axel). While looking back on these inventions is certainly pretty cool, I’ve been particularly interested in Hero’s work on ‘automata’ - machines that can move on their own accord. Hero specifically wrote about how to make two types of automated theatres in his volume &lt;em&gt;On Automata.&lt;/em&gt; As someone who works in programming and technology, it can be humbling and interesting to look back and see how people ‘programmed’ 2000 years ago, and what they used these complex devices for. As such, in this post, I’m going to go back and look very briefly at automata in Homer, and then take a look at the two automata discussed in Hero’s treatise &lt;em&gt;On Automata,&lt;/em&gt; providing a short summary and discussion for both. Check out my bibliography at the end of the post for more sources if you’re interested in all this!&lt;/p&gt;

&lt;figure style=&quot;display: inline-block; width: 33%; vertical-align: top&quot;&gt;
&lt;img src=&quot;https://imgur.com/dUsD7ls.png&quot; style=&quot;margin: 0 auto;&quot; /&gt;
&lt;figcaption&gt;An illustration of the Aeolipile from Knight's American Mechanical Dictionary, from Wikipedia.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure style=&quot;display: inline-block; width: 33%; vertical-align: top&quot;&gt;
&lt;img src=&quot;https://i.imgur.com/owrS85F.png&quot; style=&quot;margin: 0 auto; margin-top: 1em&quot; /&gt;
&lt;figcaption&gt;An illustration of the holy water vending machine designed by Hero. &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure style=&quot;display: inline-block; width: 32%; vertical-align: top&quot;&gt;
&lt;img src=&quot;https://i.imgur.com/O1OUHW0.png&quot; style=&quot;margin: 0 auto; margin-bottom: 2em; margin-top: 3em&quot; /&gt;
&lt;figcaption&gt;Automata of Hercules hitting head of the dragon, done by Giovanni Battista Aleoti.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Automata in ancient times were likely thought of quite differently from how we might think about ‘robots’ today: this was a time before electricity and computers, and so the modern notion of a machine holding circuits and powered by some internal battery did not yet exist. Mentions of automata date back to Homer, the most obvious and notable being the self-moving tripods and robotic assistants Hephaestus crafts in the &lt;em&gt;Iliad&lt;/em&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Self-moving tripods (Book XVIII, 372–377 - iliad)&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;τὸν δ᾽ εὗρ᾽ ἱδρώοντα ἑλισσόμενον περὶ φύσας&lt;/p&gt;

      &lt;p&gt;σπεύδοντα: τρίποδας γὰρ ἐείκοσι πάντας ἔτευχεν&lt;/p&gt;

      &lt;p&gt;ἑστάμεναι περὶ τοῖχον ἐϋσταθέος μεγάροιο,&lt;/p&gt;

      &lt;p&gt;χρύσεα δέ σφ᾽ ὑπὸ κύκλα ἑκάστῳ πυθμένι θῆκεν,&lt;/p&gt;

      &lt;p&gt;ὄφρά οἱ αὐτόματοι θεῖον δυσαίατ᾽ ἀγῶνα&lt;/p&gt;

      &lt;p&gt;ἠδ᾽ αὖτις πρὸς δῶμα νεοίατο θαῦμα ἰδέσθαι.&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;blockquote&gt;
      &lt;p&gt;And she [Thetis] found him [Hephaestus] sweating, hurrying about&lt;/p&gt;

      &lt;p&gt;his bellows, as he was crafting tripods, twenty in all,&lt;/p&gt;

      &lt;p&gt;to stand around the wall of his well-built hall,&lt;/p&gt;

      &lt;p&gt;and he had fitted golden wheels beneath the base of each&lt;/p&gt;

      &lt;p&gt;so that they on their own enter the meeting of the gods,&lt;/p&gt;

      &lt;p&gt;and then would be able to again return back to his house, a wonder to behold.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Robot assisstants (Book XVIII, 410–420, Illiad)&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;… ὑπὸ δ᾽ ἀμφίπολοι ῥώοντο ἄνακτι&lt;/p&gt;

      &lt;p&gt;χρύσειαι ζωῇσι νεήνισιν εἰοικυῖαι.&lt;/p&gt;

      &lt;p&gt;τῇς ἐν μὲν νόος ἐστὶ μετὰ φρεσίν, ἐν δὲ καὶ αὐδὴ&lt;/p&gt;

      &lt;p&gt;καὶ σθένος, ἀθανάτων δὲ θεῶν ἄπο ἔργα ἴσασιν.&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;blockquote&gt;
      &lt;p&gt;And attendants moved, supporting their lord&lt;/p&gt;

      &lt;p&gt;golden ones, like living young women.&lt;/p&gt;

      &lt;p&gt;They had sense and reason, and speech&lt;/p&gt;

      &lt;p&gt;and strength, and knowledge of handiwork from the immortal gods.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(Translations by me)&lt;/p&gt;

&lt;p&gt;Also worth noting are Hephaestus’ automatic bellows (Book XVIII, 470–473, Illiad) and the Phaeacian’s mind-reading automatic ships (Book VIII, 555–563, Odyssey). &lt;a href=&quot;https://static1.squarespace.com/static/57e9726bbebafb818eaa5a1a/t/592db40ebebafbf65e52d753/1496167440162/Religious+Life+Greek+Automata.pdf&quot;&gt;At the time of writing these automata may have been thought of purely in magical terms, but later on (e.g. by Hero’s time), such things would have been linked with the technical.&lt;/a&gt; While we can’t assume that Homer thought of these things in mechanical terms, the links are striking and interesting: the tripods explicitly have wheels and are linked with Hephaestus, who explicitly constructs things and is a craftsman. As such, even if originally these devices were dreamt of as magic, they undoubtedly served as inspiration for creators like Hero, who developed the techniques to make things like self-moving tripods a reality.&lt;/p&gt;

&lt;p&gt;Either way, the notion of automata has been around for a long time, and Hero was by far not the first inventor to build them. Rather, he is another in a group of automata-makers, who built on each others’ work. Other big names in ancient automata were &lt;a href=&quot;https://en.wikipedia.org/wiki/Philo_of_Byzantium&quot;&gt;Philo of Byzantium&lt;/a&gt;, who Hero explicitly names and builds off, and &lt;a href=&quot;https://en.wikipedia.org/wiki/Ctesibius&quot;&gt;Ctesibius&lt;/a&gt;, who invented an early form of the pipe organ and is credited with ‘inventing’ pneumatics. As we will see, Hero is quite open about using techniques invented by others, and his own fame is likely more a function of more of his work surviving, rather than him being more skilled (although he certainly was quite skilful).&lt;/p&gt;

&lt;h2 id=&quot;on-automata&quot;&gt;&lt;em&gt;On Automata&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;On Automata&lt;/em&gt; was a treatise written by Hero, and is split into two books: the first describes what he dubs a ‘mobile automaton’ and the second describes a ‘stationary automaton’. It appears to mainly be a sort of instruction/explanation manual, with the end cut off. For a more in-depth look at the manuscript tradition surrounding it, I suggest reading &lt;a href=&quot;http://theses.gla.ac.uk/76774/&quot;&gt;Grillo’s PhD thesis&lt;/a&gt;, which goes into detail on this history. I’ve used their adaption of the text below when translating the original Greek.&lt;/p&gt;

&lt;h2 id=&quot;the-mobile-automaton&quot;&gt;The Mobile Automaton&lt;/h2&gt;

&lt;p&gt;The mobile automaton is essentially a mobile diorama of sorts: a shrine (of sorts) of Dionysus with features like dancing figures and self-lighting fires. The diorama/shrine itself moves (and hence is a mobile automaton), moving in a straight line, performing a scene, and then moving back, with everything going back to their starting locations, allowing re-use. Interestingly, Hero describes different motions possible for the automata, including a rectangular and ‘snake-like’ motion. It’s debated where this sort of automaton would be displayed, but both at private parties and public theatres seems plausible. Hero’s description of the automata is in some ways closer to a textbook than an exact manual: he provides different ideas for different movements and setups, looking not to provide an exact schematic for a single device, but rather illustrate a series of different mechanisms and systems that can be put together to create these sorts of automata:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;ἐν μὲν οὖν τούτῳ τῷ βιβλίῳ περὶ τῶν ὑπαγόντων γρά- φομεν ἐκθέμενοι διάθεσιν ποικίλην κατά γε ἡμᾶς, ἥτις ἁρμόσει πάσῃ διαθέσει πρὸς τὸ δύνασθαι τὸν προαιρούμενον ἑτέρως διατίθεσθαι μηδὲν ἐπιζητοῦντα πρὸς τὴν τῆς διαθέσεως ἐνέργειαν·&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;So, In this book, I am writing about mobile automata, setting out an intricate design of my own, which will fit to all other arrangements, such that whoever wants to arrange it differently will be able to, without needing anything else for the creation of the arrangement.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(I.8, translation mine)&lt;/p&gt;

&lt;p&gt;So, let’s go through these various systems in order (chapter numbers and paragraphs given in brackets). In order, Hero describes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The area and material requirements of the automaton - i.e. what sort of material to build it out of (light timber, bronze and iron, etc) and where to put it (if possible, a flat even surface). (1.II.1-5)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A broad description of the central mechanic of both the stationary and mobile automata: counterweights, with rope wound around axles. The counterweight rests on millet/mustard (or dry sand for the stationary automata) in a tube. At runtime, the millet or mustard is slowly drained from the bottom, allowing the counterweight and an attached rope to descend, causing the rope to spin any axles it’s attached to. (1.II.6-1.IV)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The rough design of the automata, illustrated below. Some rough measurements are given. (1.IV)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/NOoctEm.png&quot; style=&quot;margin: 0 auto; width: 30%&quot; /&gt;

&lt;figcaption&gt;Diagram of Hero's mobile automaton, from Grillo's PhD thesis (fig 1).&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;A short description of the performance, which I give in full below, as it is quite interesting. Hero also mentions the automata must be kept small to avoid the suspicion that a human is actually working it. (1.IV)&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;(1) Τούτων δὲ οὕτως ὑπαρχόντων ἐν ἀρχῇ τεθέντος τοῦ αὐτομάτου ἐπί τινα τόπον καὶ ἀποστάντων &amp;lt;ἡμῶν&amp;gt; μετ ̓ οὐ πολὺν χρόνον ὑπάξει τὸ αὐτόματον ἐπί τινα ὡρισμένον τόπον. καὶ στάντος αὐτοῦ ἀνακαυθήσεται ὁ κατάπροσθεν τοῦ Διονύσου βωμός. καὶ ἐκ μὲν τοῦ θύρσου τοῦ Διονύσου ἤτοι γάλα ἢ ὕδωρ ἐκπυτισθήσεται, ἐκ δὲ τοῦ σκύφους οἶνος ἐκχυθήσεται ἐπὶ τὸν ὑποκείμενον πανθηρίσκον.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;(2) στεφανωθήσεται δὲ πᾶς ὁ παρὰ τοὺς τέσσαρας κίονας τῆς βάσεως τόπος. αἱ δὲ περικύκλῳ Βάκχαι περιελεύσονται χορεύουσαι περὶ τὸν ναΐσκον. καὶ ἦχος ἔσται τυμπάνων καὶ κυμβάλων. καὶ μετὰ ταῦτα σταθέντων τῶν ἤχων ἀποστραφήσεται τὸ τοῦ Διονύσου ζῴδιον εἰς τὸ ἐκτὸς μέρος. ἅμα δὲ τούτῳ καὶ ἡ ἐπικειμένη τῷ πυργίῳ Νίκη συνεπιστραφήσεται.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;(3) καὶ πάλιν ὁ ἔμπροσθεν γεγονὼς τοῦ Διονύσου βωμός, πρότερον δὲ ὀπίσθιος ὑπάρχων ἀνακαυθήσεται. καὶ πάλιν ἐκ μὲν τοῦ θύρσου ὁ ἀναπυτισμὸς ἔσται, ἐκ δὲ τοῦ σκύφους ἡ ἔκχυσις. καὶ πάλιν αἱ Βάκχαι χορεύσουσι περιερχόμεναι τὸν ναΐσκον μετὰ ψόφου τυμπάνων καὶ κυμβάλων. καὶ πάλιν σταθεισῶν αὐτῶν τὸ αὐτόματον ἀναχωρήσει εἰς τὸν ἐξ ἀρχῆς τόπον.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;(1) And with things in this way, at first the automaton is placed in a spot, and while we are standing away (from it), after a short time the automaton will move to a defined location. And once it stands still, the altar in front of Dionysus will flare up. And either milk or water will flow out of Dionysus’ &lt;a href=&quot;https://en.wikipedia.org/wiki/Thyrsus&quot;&gt;thyrsus&lt;/a&gt;, and wine will flow out of his cup onto the panther lying below.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;(2) And every place near the four columns of the altar will be crowned (with garlands). And the bacchantes all around will go around the shrine, dancing. And there will be a sound of kettledrums and cymbals. After this, when the sound has halted, the figurine of Dionysus will turn to the outside. At the same time as this, the Nike placed on the cupola will turn together with it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;(3) And again, the alter, which is in front of Dionysus and before was behind him, will flare up. And again there will be the spurt from the thyrsus and the outpour from the cup. And again the bacchantes will dance going around the shrine with the noise of kettledrums and cymbals. And again, when they have come to a stop, the automaton will go back to the place it started.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;After this, we come to descriptions of how to make motion (the more complex of which may not actually work well in practice):&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Motion forward and back (1.V-VI), with allowances for pauses. This is done by wounding rope in particular ways and adding some slack in certain spots for pauses.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Circular motion (1.VII-VIII), which uses axels set on angles, and wheels of different sizes.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Rectilinear motion (1.IX-X), which uses two sets of wheels, alternately raised and lowered.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;‘Snake-like’ or simply non-rectangular motion (1.XI), for which Hero describes 3 configurations. All of these essentially use the core idea of multiple independent axels for wheels, allowing different degrees of turning.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;After this, Hero turns to implementations of aspects of the performance:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Lighting the fires (XII) is done by lighting a fire (probably manually before the automaton is run) under a grate covered by a plate, and then moving the plate via the same rope-counterweight system used for everything else.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Getting milk and wine (XIII) to spurt out is done via the use of pipes and a tap system, with again ropes controlling this system.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Sound is made by pouring little balls on cymbals and drums, dropped by opening a door. (XIV).&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Garlands are dropped on the stage from trapdoors (XV), much like the balls.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;The baccantes are made to ‘dance’ by spinning them on their own wooden ring on the stage (XVI).&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;He then adds small details on how to hide the cords, showing how to split up the spaces for the millet counterweight, etc. (XVII.1-2)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;He then discusses methods for extending the range of the automation:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;First, he notes using bigger wheels or smaller axels will extend the range (XVII.3)&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Then he describes a system where the rope is wound around the smaller part of a pulley, and then onto a larger part, amplifying the rotation of later axels in the system. (XVIII)&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Finally, a brief (rough) description of a two-counterweight system is given (XIX). In this system, the one counterweight deals with forwards and backwards motions, and the other all other types of motion of the system.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And that’s the first book! It’s both a description of how to build this one specific automaton and a bit of an explanation of generic techniques that can be re-used across different designs. Personally, the way all these different mechanisms can be mixed and placed wherever feels a bit like programming: you have these sets of primitives (e.g. axels, or the fire-lighting mechanism) that are controlled largely in the same manner, through specific placement in a cord’s unwinding. While the physical aspect obviously would make it incredibly difficult to make changes on the fly or build without much pre-planning, Hero certainly presents these ideas as pre-made sub-programs for remixing. It’s important to note it’s unlikely Hero built all the movement mechanisms he describes here - &lt;a href=&quot;https://link.springer.com/chapter/10.1007/978-94-007-4132-4_13&quot;&gt;rather, not all the movement mechanisms described are physically feasible, making them likely to more be results of Hero’s own mathematical deductions as opposed to empirical results&lt;/a&gt;.  Another interesting aspect is the way mathematical ideas are described. Hero is fairly geometric in his descriptions, with the most common formula being ἔστω + a geometric label, for example:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;ἔστω γὰρ πλινθίον τὸ α̅βγ̅δ̅; ἐν ᾧ ἄξων ἔστω ὁ εζ̅̅ συμφυεῖς ἔχων τροχοὺς τοὺς η̅θ; κ̅λ; ὁ δὲ τρίτος τροχὸς ἔστω ὁ μν̅.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Let there be a case, αβ̅γ̅δ̅; in which let there be an axle, εζ̅, with wheels attached to it, η̅θ̅ and κ̅λ; let there be the third wheel, μν̅.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(translation mine)&lt;/p&gt;

&lt;p&gt;There’s some debate on exactly how to translate ἔστω here which I am not qualified to weigh in on, but I’ll just note that it does &lt;em&gt;feel&lt;/em&gt; similar to how we write out geometrical descriptions nowadays (‘let there be a line X…’).&lt;/p&gt;

&lt;p&gt;Finally, I’d like to note Hero’s eye to showmanship, with him dedicating some time to discuss how to hide the mechanisms of the automaton, and even from the outset fronting that these automata are things that inspire and generate wonder in others. Indeed, as an automatic theatre-constructor, Hero here is acting as stage director and engineer at the same time. Even from the outset of invention, we see innovation arising not to serve functional needs, but rather as a way to express creativity in unique ways.&lt;/p&gt;

&lt;h2 id=&quot;the-stationary-automaton&quot;&gt;The Stationary Automaton&lt;/h2&gt;

&lt;p&gt;The stationary automaton is essentially a box that is able to display a series of scenes, acting like a mini theatre, containing painted images with moving elements (e.g. arms sticking out and moving, or figurines moving in front of a backdrop), and the box opening and closing on its own to facilitate scene transitions. It seems likely this sort of automaton was used in private parties as a form of entertainment. Let’s get into Hero’s description of it.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;First, Hero notes that the description and work in the mobile automata were more original, and explicitly notes that in his stationary work he is working off what Philo had already done. He both criticises and praises aspects of Philo’s previous work. (XX)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;He then very briefly describes the stationary automata in general: boxes that open and shut to show a series of different scenes with moving, painted figures (XXI).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;He then talks about old stationary automata and one particular one he saw that impressed him, telling a story about the mythological hero Naupilus (XXII). He describes the set of scenes shown by the box, and it is its construction that the rest of this book relates. The scenes go as follows:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Book XXII.3-6&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;(3) καθὰ δὲ προεθέμην, ἐρῶ περὶ ἑνὸς πίνακος τοῦ δοκοῦντός μοι κρείττονος. μῦθος μὲν ἦν τεταγμένος ἐν αὐτῷ ὁ κατὰ τὸν Ναύπλιον. τὰ δὲ κατὰ μέρος εἶχεν οὕτως· ἀνοιχθέντος ἐν ἀρχῇ τοῦ πίνακος ἐφαίνετο ζῴδια γεγραμμένα δώδεκα· ταῦτα δὲ ἦν εἰς τρεῖς στίχους διῃρημένα· ἦσαν δὲ οὗτοι πεποιημένοι τῶν Δαναῶν τινες ἐπισκευάζοντες τὰς ναῦς καὶ γινόμενοι περὶ καθολκήν.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;(4) ἐκινεῖτο δὲ ταῦτα τὰ ζῴδια τὰ μὲν πρίζοντα, τὰ δὲ πελέκεσιν ἐργαζόμενα, τὰ δὲ σφύραις, τὰ δὲ ἀρίσι καὶ τρυπάνοις χρώμενα &amp;lt;καὶ&amp;gt; ψόφον ἐποίουν πολύν, καθάπερ ἐπὶ τῆς ἀληθείας {γίνοιτο}. χρόνου δὲ ἱκανοῦ διαγενομένου κλεισθεῖσαι πάλιν ἠνοίγησαν αἱ θύραι, καὶ ἦν ἄλλη διάθεσις· αἱ γὰρ νῆες ἐφαίνοντο καθελκόμεναι ὑπὸ τῶν Ἀχαιῶν. κλεισθεισῶν δὲ καὶ πάλιν ἀνοιχθεισῶν, οὐδὲν ἐφαίνετο ἐν τῷ πίνακι πλὴν ἀέρος γεγραμμένου καὶ θαλάσσης.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;(5) μετὰ δὲ οὐ πολὺν χρόνον παρέπλεον αἱ νῆες στολοδρομοῦσαι· καὶ αἱ μὲν ἀπεκρύπτοντο, αἱ δὲ ἐφαίνοντο. πολλάκις δὲ παρεκολύμβων καὶ δελφῖνες ὁτὲ μὲν εἰς τὴν θάλατταν καταδυόμενοι, ὁτὲ δὲ φαινόμενοι, καθάπερ ἐπὶ τῆς ἀληθείας. κατὰ μικρὸν δὲ ἐφαίνετο χειμέριος ἡ θάλασσα, καὶ αἱ νῆες ἔτρεχον συνεχῶς. κλεισθέντος δὲ πάλιν καὶ ἀνοιχθέντος, τῶν μὲν πλεόντων οὐδὲν ἐφαίνετο, ὁ δὲ Ναύπλιος τὸν πυρσὸν ἐξηρκὼς καὶ ἡ Ἀθηνᾶ παρεστῶσα·&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;(6) καὶ πῦρ ὑπὲρ τὸν πίνακα ἀνεκαύθη, ὡς ἀπὸ τοῦ πυρσοῦ φαινομένης ἄνω φλογός. κλεισθέντος δὲ καὶ πάλιν ἀνοιχθέντος, ἡ τῶν νεῶν ἔκπτωσις ἐφαίνετο καὶ ὁ Αἴας νηχόμενος, μηχανὴ τε {καὶ} ἄνωθεν τοῦ πίνακος ἐξήρθη καὶ βροντῆς γενομένης ἐν αὐτῷ τῷ πίνακι κεραυνὸς ἔπε- σεν ἐπὶ τὸν Αἴαντα, καὶ ἠφανίσθη αὐτοῦ τὸ ζῴδιον. καὶ οὕτως κλεισθέντος καταστροφὴν εἶχεν ὁ μῦθος. ἡ μὲν οὖν διάθεσις ἦν τοιαύτη.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;(3) As I laid out before, I will talk about one box that seems superior to me. The story set in it was the one about Naupilius. And its parts went like this. In the beginning, when the box opened, 12 painted figurines appeared. These were divided into 3 rows; and these were made to represent some of the Danaans (Greeks) preparing their ships and launching them.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;(4) These figurines moved, some sawing, some working with axes, some with hammers, and some with bow-drills and augers. They made much notice, just as it would be in reality. And once enough time had passed, the doors closed again and opened, and there was another arrangement; the ships, in fact, appeared being launched by the Achaeans (Greeks). And after the doors closed and opened again, nothing appeared in the box except the painted sky and sea.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;(5) And not long after the ships sailed along in line. Some were out of sight, and others were visible. Often dolphins swam along too, sometimes plunging into the sea, sometimes appearing, just like in real life. And gradually the sea appeared stormy, and the ships ran uninterrupted. And after the doors shut and opened again, none of the sailing ships were visible, but Naupilius holding up the torch and Athena standing alongside (were visible).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;(6) And a fire was lit up above the box, as if a flame appeared above from the torch. And after the doors closed and opened, the wreck of the ships appeared, and Ajax swimming; and a machine was raised above the box, and while there was thunder in the box itself, lightning fell on Ajax and his figure vanished. And thus, once the doors closed, the story came to an end. So, such was the arrangement.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;He then starts his description of how to construct this by starting with general design and materials for the box, and the key element of the stationary automaton: the doors that swing open and shut automatically (XXIII). As before, this is done with a counterweight along with a series of knobs and axles and carefully wound rope.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The following chapters then go through the implementation of each scene above:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;First, greeks repairing their ships (XXIV). They are painted on, with their right arms attached to a star-shaped wheel to turned by a counterweight to make the arms swing up and down (i.e. swinging hammers or similar tools to build their ships)&lt;/li&gt;
    &lt;/ul&gt;
    &lt;figure&gt;
  &lt;img src=&quot;https://i.imgur.com/0YhhlLm.png&quot; style=&quot;margin: 0 auto; width: 80%&quot; /&gt;

  &lt;figcaption&gt;Diagram of the above counterweight, taken from Grillo's Thesis.&lt;/figcaption&gt;
  &lt;/figure&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Second, the launching of the ships (XXV). The transition from the previous scene is achieved by painting this new scene on a cloth and using a rod as a weight. The same counterweight system is then used to release it at a particular time, changing the scene. This mechanism is used to transition to the fourth and fifth scenes too.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Third, the ships sailing (XXVI-XXVII). The sky and sea here are painted onto papyrus, which itself is attached to rollers on either side, allowing them to move back and forth and so make it look like the ships below (painted on cloth) are moving along. Dolphins are added on top of this, attached to a pulley inside the system that makes them swing up into the scene and then down, as if they were swimming alongside the ships.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Fourth, Naupilus and Athena (XXVIII). This is painted on cloth, and Naupilus’s torch is made by lighting some wood shavings using a small fire hidden inside the box, very much like how Dionysus’ alter was lit above.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Finally, the shipwreck (XXIX-XXX.6). Athena is placed on a base, which is flipped up and down via cords while she rotates on the base. A painted figure of Ajax swimming is present on top of the background. The lightning is made by dropping a board with some painting on it (by holding the board up with string and then dropping it), and at the same time as this falls, the figure of Ajax is covered with a cloth painted the same colour as the background, making him effectively vanish as he is struck by lightning.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;There is then a brief (one paragraph long) cut off epilogue (XXX.7), noting that these movements and the box are managed through the same means.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While potentially less exciting than the mobile automata (since it doesn’t move), the stationary automata is actually more intricate in some ways, telling a full story across more scenes than the mobile, while still highlighting the versatility of the counterweight-style system. It’s also worth highlighting this automaton was not Hero’s invention, but Philo’s, showing how there were a few people using these ideas and mechanisms to devise their own automata art (in fact, Philo likely predates Hero, and as such Hero likely learnt many of these techniques from Philo). Again, the artistic and the mechanical is blended in this automaton, with the focus on giving a good show to an audience, rather than solving some specific problem or issue. Beyond this, the presentation and ideas used share a lot with the mobile automaton. Personally, I think a seven-scene story is probably more exciting to watch than the relatively simple automated mobile shrine above, even if the fact the mobile shrine moves on its own is fairly impressive. It’s fun to think about what you could potentially ‘program’ into this type of automata, and the length of the stories you could tell - was watching this an ancient version of watching the latest blockbuster with the newest and best SFX? (probably not). Overall, the mobile automaton is just as technically impressive as the mobile one, with a complex story being told.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Hero’s &lt;em&gt;On Automata&lt;/em&gt;, to me, exposes a lot of interesting ideas and facts about ancient innovation, mathematics, and how people thought about automation. Interesting, I think it links more to computer animation and computer art than it does artificial intelligence, despite the name of ‘automata’. The focus is on creating awe and wonder, hiding the mechanical truths to get the audience to focus on the little stories told by these complex and intricate devices. The use of this early style of programming, and coming up with novel ways to use a central system to create new effects reminds me a lot of how blockbusters have often involved the creation of new technology to achieve a director’s vision. Perhaps this exposes a core element of human innovation, dating back to Homer and his automata: technological and artistic creation are somehow innately linked.&lt;/p&gt;

&lt;p&gt;So that’s Hero’s &lt;em&gt;On Automata&lt;/em&gt;. There’s a lot of generic posts on Hero out there on the internet, but actual in-depth resources require a bit more digging, so I hope this post is able to show you something you didn’t previously know in a reasonable amount of detail. I’m certainly not an expert in this space - see my bibliography for the real experts - but nonetheless I hope my reasonably unique experience as a classicist and software developer has provided a unique view. If you want to read further, in particular, I found &lt;a href=&quot;http://theses.gla.ac.uk/76774/&quot;&gt;Francesco Grillo’s PhD thesis&lt;/a&gt; on the first book of &lt;em&gt;On Automata&lt;/em&gt; very thorough and informative for not just the book itself, but Hero’s life and context as a whole (as you might have guessed from my constant references to it above). Hope to see you around for my next post!&lt;/p&gt;

&lt;h3 id=&quot;bibliography&quot;&gt;Bibliography&lt;/h3&gt;

&lt;p&gt;Bosak-Schroeder, Clara. “The Religious Life of Greek Automata.” &lt;em&gt;Archiv Für Religionsgeschichte&lt;/em&gt;, vol. 17, no. 1, Dec. 2016, pp. 123–36. DOI.org (Crossref), doi:10.1515/arege-2015-0007.&lt;/p&gt;

&lt;p&gt;Grillo, Francesco. &lt;em&gt;Hero of Alexandria’s Automata: A Critical Edition and Translation, Including a Commentary on Book One&lt;/em&gt;. University of Glasgow, 2019.&lt;/p&gt;

&lt;p&gt;Knight, Edward Henry. &lt;em&gt;Knight’s American Mechanical Dictionary&lt;/em&gt;. http://onlinebooks.library.upenn.edu/webbin/book/lookupid?key=olbp69570.&lt;/p&gt;

&lt;p&gt;McCourt, Finlay. “An Examination of the Mechanisms of Movement in Heron of Alexandria’s On Automaton-Making.” &lt;em&gt;Explorations in the History of Machines and Mechanisms&lt;/em&gt;, edited by Teun Koetsier and Marco Ceccarelli, vol. 15, Springer Netherlands, 2012, pp. 185–98. DOI.org (Crossref), doi:10.1007/978-94-007-4132-4_13.&lt;/p&gt;

&lt;p&gt;Sherwood, Andrew N., et al. &lt;em&gt;Greek and Roman Technology: A Sourcebook: Annotated Translations of Greek and Latin Texts and Documents&lt;/em&gt;. Routledge, 2003. DOI.org (Crossref), doi:10.4324/9780203413258.&lt;/p&gt;</content><author><name></name></author><category term="blog" /><category term="non-technical" /><summary type="html">Hero (or Heron) of Alexandria was a famous ancient inventor, who lived around the first century AD (i.e. early Roman empire). As you might already know from the numerous blogs and articles about him on the internet, he invented a bunch of fairly interesting mechanisms - an early toy steam engine (widely regarded as the first steam engine), self-moving theatres, the first vending machine (to dispense holy water), and arguably an early programmable cart (programmable via placing pegs on an axel). While looking back on these inventions is certainly pretty cool, I’ve been particularly interested in Hero’s work on ‘automata’ - machines that can move on their own accord. Hero specifically wrote about how to make two types of automated theatres in his volume On Automata. As someone who works in programming and technology, it can be humbling and interesting to look back and see how people ‘programmed’ 2000 years ago, and what they used these complex devices for. As such, in this post, I’m going to go back and look very briefly at automata in Homer, and then take a look at the two automata discussed in Hero’s treatise On Automata, providing a short summary and discussion for both. Check out my bibliography at the end of the post for more sources if you’re interested in all this!</summary></entry><entry><title type="html">Reinforcement Learning with Pokemon</title><link href="https://hamishivi.github.io/2021/08/02/pokerl.html" rel="alternate" type="text/html" title="Reinforcement Learning with Pokemon" /><published>2021-08-02T00:00:00+00:00</published><updated>2021-08-02T00:00:00+00:00</updated><id>https://hamishivi.github.io/2021/08/02/pokerl</id><content type="html" xml:base="https://hamishivi.github.io/2021/08/02/pokerl.html">&lt;p&gt;As a big Pokemon fan (which I have been ever since my parents gave me pokemon ruby as a young child), I’ve always enjoyed going on &lt;a href=&quot;https://play.pokemonshowdown.com/&quot;&gt;Pokemon Showdown&lt;/a&gt; for some quick random games when I need a Pokemon fix. For those of you who don’t know about showdown, it’s an online pokemon battle simulator - you can create pokemon teams, or generate a random team, and play against others on the internet. It’s fairly easy to use and straightforward, and is open source! So this got me wondering: &lt;strong&gt;can we make a bot play pokemon?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Now, this isn’t a new idea: there are a fair few blog posts and papers looking at pokemon battle AI. In fact, as it turns out, there are a few good pokemon AI libraries that interface with showdown. For this project, I used the &lt;a href=&quot;https://github.com/hsahovic/poke-env&quot;&gt;poke-env library&lt;/a&gt;, since it works with the &lt;a href=&quot;https://gym.openai.com/&quot;&gt;OpenAI gym API&lt;/a&gt;. This allowed me to hook it into &lt;a href=&quot;https://stable-baselines3.readthedocs.io/&quot;&gt;the stable baselines 3 library&lt;/a&gt; for easy reinforcement learning. All you need to do is specify how to turn a battle into a vector, what algorithm to use, and set some hyperparameters! I’ll give an outline on how to do this and get started in this post, and provide some results from my initial attempts.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;🧑‍💻 You can find my code &lt;a href=&quot;https://github.com/hamishivi/stunfisk-rl&quot;&gt;here&lt;/a&gt;!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;reinforcement-learning&quot;&gt;Reinforcement Learning?&lt;/h2&gt;

&lt;p&gt;Before we get into the pokemon side of things, let’s briefly go over reinforcement learning (RL), a paradigm for making game-playing AIs. There are many comprehensive and fantastic RL overviews out there I recommend checking out, such as &lt;a href=&quot;https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html&quot;&gt;this one&lt;/a&gt;, so I’m going to give a very basic explanation.&lt;/p&gt;

&lt;p&gt;At its most basic, reinforcement learning is a method for learning strategies to maximise some cumulative reward. There are four key parts to this:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Environment&lt;/strong&gt; - We must have some environment that algorithms/programs can operate in. In our case, the ‘environment’ would be a pokemon battle! This is a snapshot of the game state at some point in time (in our case, at the start of our turn).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Actions&lt;/strong&gt; - These are the things that we can do to influence the environment. This might be moving a character around, or in our case, choosing a move.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Rewards&lt;/strong&gt; - We will have some desired outcomes (e.g. winning a game, collecting gold, or dealing damage to an opponent) that the environment is designed to give rewards for. These are the outcomes we want to maximise over time. In our case, this is simply our win rate, but we can also incentivise our AI to deal more damage, or knock out as many opponent pokemon as it can.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Agent&lt;/strong&gt; - A system or algorithm that takes in an environment state, chooses an action, and then receives some (or no) reward based on that. You can think of the agent as a ‘player’ of whatever game we are looking at.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Given these four things, we can see how our agent ‘plays’ a game: Our agent receives an environment state, picks an action based on it, then (potentially) receives some reward, and repeats this until the game is over or we terminate the program. How our agent picks an action is up to us - in our case, we’ll be using neural networks that receive information on the battle in numerical form and provide scores for each action.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/CZ4QQVU.png&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;RL process, from https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Why use RL and neural networks here, and not use a more classical game-playing algorithm (e.g. minimax, which just calculates some number of moves ahead)? Well, in Pokemon we have &lt;strong&gt;imperfect information&lt;/strong&gt; and &lt;strong&gt;a massive number of game states&lt;/strong&gt;. We have imperfect information because we don’t know the opponent’s pokemon until they send them out, and even then don’t know certain details (stats, items, moves) until they explicitly come into play. We have a massive number of game states because the number of possible pokemon, move, item, etc. choices and outcomes in any battle is massive - the damage from a move is slightly probabilistic, moves can miss, and so on. Due to this, simulating ahead any number of moves is difficult (due to the missing information) and quickly becomes complex (due to the large number of possible outcomes for any given action). As such, reinforcement learning is a good choice for learning how to play Pokemon battles - it can learn how to make good guesses at the best move given imperfect information, and does not require us to simulate all possible future moves. Rather, it will learn by playing itself.&lt;/p&gt;

&lt;h2 id=&quot;how-to-make-a-machine-see-pokemon&quot;&gt;How to make a machine ‘see’ Pokemon?&lt;/h2&gt;

&lt;p&gt;Before we start running RL algorithms, we need to convert our Pokemon battles to a format they can understand. Famously, &lt;a href=&quot;https://arxiv.org/pdf/1312.5602v1.pdf&quot;&gt;Deepmind trained an RL agent to play Atari games directly using screenshots from the games themselves&lt;/a&gt;, but since we have direct access to the stats and other values used by the battle engine, we can just use that - it’s a lot easier for the network to learn directly from these values rather than have to learn how to work out these values from the screen and then learn how to interpret them. So, we’re going to represent every pokemon via numeric values only (since a neural network can only process, well, numbers). This means, at every turn in the game, we need to convert the game state into a set of numbers representing the current state of the game, and then feed this into our RL agent, which will then pick a move as output. These numbers are how our agent will ‘see’ the game, so we need to make sure:&lt;/p&gt;

&lt;p&gt;(a) the values contain the information needed to play pokemon effectively, and&lt;/p&gt;

&lt;p&gt;(b) the agent is able to correctly parse the values and learn how to make use of them to play pokemon.&lt;/p&gt;

&lt;p&gt;This is just &lt;strong&gt;feature selection&lt;/strong&gt;, which is a very classic task in ‘real-world’ machine learning: what values do we pick, and how do we represent them, such that our pokemon agent can do its job well? Neural networks and training will help us here since they can learn &lt;em&gt;how to construct&lt;/em&gt; effective representations from raw data, but we still need to convert our non-numeric data (types, abilities, items, etc.) to a useful numeric form, and determine the best overall way to layout both the data and the network so it can effectively learn the best representations. We want to give our network all the help we can give it!&lt;/p&gt;

&lt;p&gt;To highlight this, for example, we could try to get our agent to (a) &lt;em&gt;learn the pokemon type system on its own&lt;/em&gt;, or (b) &lt;em&gt;give it a feature that indicates if a move will be supereffective.&lt;/em&gt; We might want to help the agent here since types are incredibly important to Pokemon’s battle system, and learning the type system on its own might prove difficult. In fact, I tested this out below and generally found that providing this feature sometimes gave a small boost. This intuitively makes sense: a strategy that just chooses the most super effective move at each point will probably get you through most of any given pokemon game. As such, for a complex game like pokemon, even with neural nets (which theoretically can learn all this on their own), being smart about the information we provide can give our agent a leg up.&lt;/p&gt;

&lt;h2 id=&quot;coding-this-up&quot;&gt;Coding this Up&lt;/h2&gt;

&lt;p&gt;So, how do we code this all up? Well, it’s actually really easy! I made use of two libraries mentioned above: &lt;a href=&quot;https://github.com/hsahovic/poke-env&quot;&gt;poke-env&lt;/a&gt; and &lt;a href=&quot;https://stable-baselines3.readthedocs.io/en/master/&quot;&gt;stable-baselines3&lt;/a&gt;. The first gives us an OpenAI gym wrapper around pokemon showdown for easy use, and the second provides implementations of popular RL algorithms that we can just plug and play with. The only part we need to write is the code that converts a pokemon battle object (as defined in poke-env) into an ‘observation’ - a set of numbers representing a game state at a particular move.&lt;/p&gt;

&lt;p&gt;How I did this was to first define a basic RL poke-env player &lt;a href=&quot;https://poke-env.readthedocs.io/en/latest/rl_with_open_ai_gym_wrapper.html&quot;&gt;similar to the one shown in the poke-env tutorial:&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleRLPlayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Gen8EnvSinglePlayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    Class to handle the interaction between game and algo
    Main 'embedding' handled by BattleConverter class
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cfg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cfg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cfg&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BattleConverter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cfg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;observation_space&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_observation_space&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_box&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spaces&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Discrete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_space&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cur_bat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;

    &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;property&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;action_space&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_box&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;embed_battle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;battle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;battle_to_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;battle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute_reward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;battle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reward_computing_helper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;battle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;fainted_value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cfg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;REWARD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FAINTED&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;hp_value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cfg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;REWARD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;victory_value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cfg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;REWARD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VICTORY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;‘cfg’ is my config object, which defines hyperparameters and what features we want to use. The ‘BattleConverter’ object here is simply an object that handles all conversion from battle object to OpenAI Observation object. In our case, the observation is actually a dict that looks a bit like this:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;pokemon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pokemon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;atk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pokemon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;move&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bsp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pokemon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;move&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That is, every key represents a detail of the battle that our network will use. The ‘battle_to_tensor’ function actually does the conversion. You can also just throw everything in a ‘box’ observation object, but I think this is a bit messier. The code for this file is &lt;a href=&quot;https://github.com/hamishivi/stunfisk-rl/blob/main/battle_converter.py&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Given the above SimpleRLPlayer class, we can create a openAI environment just with:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;n&quot;&gt;env_player&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SimpleRLPlayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cfg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;battle_format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;gen8randombattle&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To train, we need to create a stable-baselines algorithm instance (in my case, using the DQN algorithm), and then use it to train an agent, like so:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DQN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;DqnMlpPolicy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;env_player&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;policy_kwargs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;policy_kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cfg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DQN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LEARNING_RATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;buffer_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cfg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DQN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BUFFER_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;learning_starts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cfg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DQN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LEARNING_STARTS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cfg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DQN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GAMMA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;tensorboard_log&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;./dqn_pokemon_tensorboard/&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;player&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_timesteps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timesteps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;env_player&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;play_against&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;env_algorithm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;opponent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RandomPlayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;battle_format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;gen8randombattle&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;env_algorithm_kwargs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;model&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The ‘play_against’ function here basically handles the actual training steps and the battle starts/stops for us. You can train against various bots (e.g. a bot that chooses random moves, as seen above) too, although I haven’t worked out how to do self-play (i.e. agents against each other) yet! ‘timesteps’ here is the number of turns we want to train for.&lt;/p&gt;

&lt;p&gt;We can evaluate our agent once we’re done training as such:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;evaluate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;player&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;player&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_battles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;evaluate_policy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;player&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_eval_episodes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eval_eps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;env_player&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;play_against&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;env_algorithm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;opponent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RandomPlayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;battle_format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;gen8randombattle&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;env_algorithm_kwargs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;model&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;env_player&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_won_battles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# number of battles won
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Pretty simple! Again, we can test against non-random agents too if we want. See my full codebase here (I’ve left out some extra steps I do, like specifying network architecture).&lt;/p&gt;

&lt;p&gt;To run this, we simply start a pokemon showdown server locally (&lt;a href=&quot;https://github.com/smogon/pokemon-showdown&quot;&gt;clone the showdown repo&lt;/a&gt; if you haven’t) and run it with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;node pokemon-showdown start --no-security&lt;/code&gt;. Then run your script and it should work! 🙂 As a fun bonus, you can go to the pokemon showdown server (localhost:8000 usually) and see your agent playing games as it trains.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/Bi4qjqj.png&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;Watching my pokemon agent train!&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;my-basic-bot&quot;&gt;My Basic Bot&lt;/h2&gt;

&lt;p&gt;As a quick initial bot, I built up a bot that uses all the main stats of a pokemon, as well as move stats, as input. Each categorical feature (so types, gender, and move category) are encoded with embedding layers. Each move feature is concatenated and passed through a move encoder, and each pokemon feature is concatenated with the encoded moves and passed through a pokemon encoder. My intuition here was to see if shared encoders would help with the model learning what stats and features are important to general pokemon battling, before using them to work out the best move.&lt;/p&gt;

&lt;p&gt;I test my model using three basic setups:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A low-level Grookey (agent) against a low-level Skwovet (bot).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Red’s Gold/Silver teams (lightly modified) for both agent and bot.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Fully randomised teams for both agent and bot.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I stuck with using the vanilla DQN algorithm for now (more discussion on this later). In each setup, the agent would be trained by playing against a pokemon-playing bot and then evaluated by playing 100 games against a similar bot. The two bots I used to train my agent against and evaluate were:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Random:&lt;/strong&gt; a bot choosing random moves at each turn. This is a bare minimum baseline - even a basic agent should be able to beat a random bot most of the time.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Max:&lt;/strong&gt; a bot that chooses the maximum damage move at every turn. This is a much harder baseline, which I imagine some players may even struggle a bit with. However, such a player would be predictable and should be beatable in many scenarios.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here’s the number of wins out of 100 games after training for 100,000 moves. The columns are in the format ‘bot agent was trained against - bot agent was evaluated against’.&lt;/p&gt;

&lt;table class=&quot;tg&quot;&gt;
&lt;thead&gt;
  &lt;tr&gt;
    &lt;th class=&quot;tg-0lax&quot;&gt;Experiment&lt;/th&gt;
    &lt;th class=&quot;tg-0lax&quot;&gt;Random - Random&lt;/th&gt;
    &lt;th class=&quot;tg-0lax&quot;&gt;&lt;span style=&quot;font-weight:400;font-style:normal&quot;&gt;Random - Max&lt;/span&gt;&lt;/th&gt;
    &lt;th class=&quot;tg-0lax&quot;&gt;&lt;span style=&quot;font-weight:400;font-style:normal&quot;&gt;Max - Random&lt;/span&gt;&lt;/th&gt;
    &lt;th class=&quot;tg-0lax&quot;&gt;&lt;span style=&quot;font-weight:400;font-style:normal&quot;&gt;Max - Max&lt;/span&gt;&lt;/th&gt;
  &lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;Grookey vs Skwovet&lt;/td&gt;
    &lt;td class=&quot;tg-buh4&quot;&gt;97&lt;/td&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;100&lt;/td&gt;
    &lt;td class=&quot;tg-buh4&quot;&gt;82&lt;/td&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;100&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;Grookey vs Skwovet (w/ type effectiveness)&lt;/td&gt;
    &lt;td class=&quot;tg-buh4&quot;&gt;56&lt;/td&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;84&lt;/td&gt;
    &lt;td class=&quot;tg-buh4&quot;&gt;90&lt;/td&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;100&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;Red vs Red&lt;/td&gt;
    &lt;td class=&quot;tg-buh4&quot;&gt;100&lt;/td&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;27&lt;/td&gt;
    &lt;td class=&quot;tg-buh4&quot;&gt;100&lt;/td&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;26&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;Red vs Red (w/ type effectiveness)&lt;/td&gt;
    &lt;td class=&quot;tg-buh4&quot;&gt;100&lt;/td&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;44&lt;/td&gt;
    &lt;td class=&quot;tg-buh4&quot;&gt;100&lt;/td&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;30&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;Full Randoms&lt;/td&gt;
    &lt;td class=&quot;tg-buh4&quot;&gt;85&lt;/td&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;47&lt;/td&gt;
    &lt;td class=&quot;tg-buh4&quot;&gt;74&lt;/td&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;28&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;Full Randoms (w/ type effectiveness)&lt;/td&gt;
    &lt;td class=&quot;tg-buh4&quot;&gt;82&lt;/td&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;49&lt;/td&gt;
    &lt;td class=&quot;tg-buh4&quot;&gt;80&lt;/td&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;40&lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;I suspected this was not enough training for the agent, so I also tried the same experiments with 1,000,000 turns, and with the type effectiveness feature (since it appeared not to hurt):&lt;/p&gt;

&lt;table class=&quot;tg&quot;&gt;
&lt;thead&gt;
  &lt;tr&gt;
    &lt;th class=&quot;tg-0lax&quot;&gt;Experiment&lt;/th&gt;
    &lt;th class=&quot;tg-0lax&quot;&gt;Random - Random&lt;/th&gt;
    &lt;th class=&quot;tg-0lax&quot;&gt;&lt;span style=&quot;font-weight:400;font-style:normal&quot;&gt;Random - Max&lt;/span&gt;&lt;/th&gt;
    &lt;th class=&quot;tg-0lax&quot;&gt;&lt;span style=&quot;font-weight:400;font-style:normal&quot;&gt;Max - Random&lt;/span&gt;&lt;/th&gt;
    &lt;th class=&quot;tg-0lax&quot;&gt;&lt;span style=&quot;font-weight:400;font-style:normal&quot;&gt;Max - Max&lt;/span&gt;&lt;/th&gt;
  &lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;Grookey vs Skwovet&lt;/td&gt;
    &lt;td class=&quot;tg-buh4&quot;&gt;88&lt;/td&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;100&lt;/td&gt;
    &lt;td class=&quot;tg-buh4&quot;&gt;61&lt;/td&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;83&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;Red vs Red&lt;/td&gt;
    &lt;td class=&quot;tg-buh4&quot;&gt;100&lt;/td&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;45&lt;/td&gt;
    &lt;td class=&quot;tg-buh4&quot;&gt;99&lt;/td&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;32&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;Full Randoms&lt;/td&gt;
    &lt;td class=&quot;tg-buh4&quot;&gt;91&lt;/td&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;57&lt;/td&gt;
    &lt;td class=&quot;tg-buh4&quot;&gt;89&lt;/td&gt;
    &lt;td class=&quot;tg-0lax&quot;&gt;47&lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Here we can see that training on the random agent for a long time often results in better results against both random and max damage bots! I imagine this is likely due to the model overfitting to the behaviour of the max bot, which is very predictable, while the more chaotic choices of the random agent may require the agent to become more flexible. This potentially suggests that a model should be trained on a random agent for a while before being trained against a more difficult bot. It’s also worth noting that the Grookey vs Skwovet battle is fairly easy to get higher win rates on, indicating how easy it is - both pokemon only have a few moves and are very low level, so as long as the agent does damage each turn they’ll usually win. As for the two harder settings, with more pokemon, we can see that beating a random agent can be done when training on either bot type, but beating the max damage bot is much, much harder. This makes sense, considering beating a max damage bot may be tough even for some players - ‘just always do as much damage as possible’ is a common strategy that’ll get you quite far in most pokemon games. That being said, I still think overall the results here are a bit disappointing - I would expect better results against the max player, given its predictability. Reruns also showed these results could be quite variable. However, there are many paths for improvements here:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;I just used a vanilla DQN algorithm, which is several years old and has many superior variants now. This is partly due to more sophisticated variants not being natively available in stable-baselines3, but given some time and work they should be possible to add. Alternatively, trying other algorithms may work well (I chose DQN as it is generally considered more sample efficient).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Training for longer helped a fair bit, and training speed could be improved by using multiprocessing. This is available in stable-baselines3 at the time of writing but requires more work in poke-env to get it to work.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;As opposed to training off multiprocessing, a more ambitious project could also look at training off existing Pokemon battles, which are available in vast quantities on pokemon showdown.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;There is much more tuning that could be done on both hyperparameters and feature selection. You can get good results with a much smaller feature set, and using simpler battle formats (e.g. fixed teams over randoms, or earlier generations with fewer battle mechanics) would also work well.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As you can see, there’s enough work here to occupy someone for months, if not much longer. I’ll certainly be revisiting this project in the future as things improve or when I have the time to dig into solving these issues! 🙂&lt;/p&gt;

&lt;h3 id=&quot;visualisation&quot;&gt;Visualisation&lt;/h3&gt;

&lt;p&gt;I like to provide demos of some sort with my projects, but hosting these pokemon bots would be a bit too much for me (I’d need a computer always connected to showdown servers), and as said I don’t think these bots are nearly good enough for human play yet.&lt;/p&gt;

&lt;p&gt;However, I did make a little &lt;a href=&quot;https://gradio.app/&quot;&gt;Gradio&lt;/a&gt; interface that allows you to explore the predictions of a bot trained on generation 5 random battles, with a limited set of input features. I used a bot with a smaller feature set to keep things more manageable in the interface (it’s clunky as is) and using generation 5 battles so the predictions would also be straightforward to understand (picking a move or switching to another pokemon, with no mega-evolutions, z-moves, or dynamaxing). You can see the model generally using the most powerful and effective moves in real-time as you alter the move stats. If you run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;move_predict_api.py&lt;/code&gt; in my codebase it will download the model and you can play with the predictions myself, like below!&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/2Hcxs1i.gif&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;Just note the outputs given say ‘%’ but are actually predicted scores. This is because the network provides &lt;em&gt;q-values&lt;/em&gt;, not predictions on the ‘right’ move. These q-values are closer to the predicted value of doing a move (based on our reward scheme). This is why all the scores tend to increase if a move’s power increases - no matter what move you choose, having that one more powerful move will make it more likely for you to win. I normalise the scores (divide by their sum) to highlight which input is being chosen (highest value) and as Gradio expects values in a [0,1] range.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Thanks for reading! I hope this was interesting, and now you know how to make your own pokemon players! As you can see, all of the hard work has actually already been done by various libraries - all you need to do is write the glue and then do the fun part of testing out different neural networks! Hope to see you around for the next post. 🙂&lt;/p&gt;</content><author><name></name></author><category term="blog" /><category term="technical" /><summary type="html">As a big Pokemon fan (which I have been ever since my parents gave me pokemon ruby as a young child), I’ve always enjoyed going on Pokemon Showdown for some quick random games when I need a Pokemon fix. For those of you who don’t know about showdown, it’s an online pokemon battle simulator - you can create pokemon teams, or generate a random team, and play against others on the internet. It’s fairly easy to use and straightforward, and is open source! So this got me wondering: can we make a bot play pokemon?</summary></entry><entry><title type="html">Wandering the Bionis</title><link href="https://hamishivi.github.io/2021/01/31/xenoblade.html" rel="alternate" type="text/html" title="Wandering the Bionis" /><published>2021-01-31T00:00:00+00:00</published><updated>2021-01-31T00:00:00+00:00</updated><id>https://hamishivi.github.io/2021/01/31/xenoblade</id><content type="html" xml:base="https://hamishivi.github.io/2021/01/31/xenoblade.html">&lt;p&gt;As our world seemingly fell apart around us in 2020, I found comfort in exploring a virtual one: the world of &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Xenoblade_Chronicles&quot;&gt;Xenoblade Chronicles&lt;/a&gt;&lt;/em&gt;. This world is a living one: the creatures of &lt;em&gt;Xenoblade&lt;/em&gt; live on the arms, shoulders, and every other part of two massive creatures called the Bionis and the Mechonis, smaller creatures living quite literally on the backs of these god-like humanoid giants.&lt;/p&gt;

&lt;p&gt;How do you build a world like this? How do you give players the sense they are exploring the body of a living creature? How do you make this world fun to explore? These questions are exactly what I’ll be taking a look at in the post, using one of &lt;em&gt;Xenoblade&lt;/em&gt;’s most famous maps, Bionis’ Leg, as a case study. I’ll look at how exploration is encouraged and made fun in the game, and how the various systems of &lt;em&gt;Xenoblade&lt;/em&gt; tie into exploring and immersing the player in the world of the Bionis and the Mechonis.&lt;/p&gt;

&lt;p&gt;As a warning, I’ll be completely spoiling the first few hours of &lt;em&gt;Xenoblade&lt;/em&gt;, up until the end of this section of the game. As such, if you’re interested in playing &lt;em&gt;Xenoblade Chronicles&lt;/em&gt; at all, I really recommend grabbing the game itself (the definitive edition came out last year on the Nintendo Switch, and there are versions for the new 3DS and Wii) and giving it a play. However, I will try to keep spoilers to a minimum, so if you’re especially curious and can’t/dont want to play the game, read on!&lt;/p&gt;

&lt;p&gt;As a brief note, all screenshots below (unless otherwise marked) are from my own new game+ playthrough of the recently-released definitive edition.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://pbs.twimg.com/media/EKKJa3uXYAMm4bQ?format=jpg&amp;amp;name=large&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;The Bionis and Mechonis standing opposite each other. &lt;a href=&quot;https://www.nintendo.com.au/catalogue/xenoblade-chronicles-3d&quot;&gt;Art from Nintendo&lt;/a&gt;.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;interacting-with-xenoblade&quot;&gt;Interacting with &lt;em&gt;Xenoblade&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;Before diving into the game world, let’s first stop to talk about &lt;em&gt;how&lt;/em&gt; we can examine exploration in &lt;em&gt;Xenoblade&lt;/em&gt;. There are two primary ways we can examine how players interact with the game:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Systemic: As a JRPG, &lt;em&gt;Xenoblade&lt;/em&gt; is a game chock full of systems. Just check out the combat: you have arts, talent arts, tension, chain attacks, status effects, auras, break/topple/daze…. there’s a lot to learn and make use of! As such, it is only natural that some of these systems tie into exploration and that exploration itself is systematised to a degree within the game.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/iIK0gQl.jpg&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;There's a lot more going on here than just what you're seeing in terms of systems.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Non-systemic: Of course, &lt;em&gt;Xenoblade&lt;/em&gt; is a game, so we have music, creature design, skyboxes, map design, and many other attributes of the game that aren’t turned into systems. These are not systems in the sense that they are elements of the game not explicitly linked to story or character progression. For example, I would count map design as ‘non-systemic’ because the map itself can’t be altered or changed via player input, but is rather something that shapes how you see and interact with the game. This isn’t a precise definition, but hopefully you get the idea.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These distinctions are not absolute (you can probably think of anything in a game as a system to some extent), but rather just a way to organise observations about the game. So, let’s start by talking about the primary ‘system’ that introduces the Bionis’ leg to the player: the main quest.&lt;/p&gt;

&lt;h2 id=&quot;systemic-interactions&quot;&gt;Systemic Interactions&lt;/h2&gt;

&lt;h2 id=&quot;the-main-quest-rescuing-juju&quot;&gt;The Main Quest: Rescuing Juju&lt;/h2&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/9lup2Ik.png&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;The Mechonis on the left, and the Bionis on the right, as represented in-game.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;After travelling up from Colony 9 (the starting area, on the Bionis’ right calf), players come up to Bionis’ leg. The thin and narrow entrance immediately leads into a massive sprawling plain: Gaur plain. Coming from the walled-off Colony 9 and closed-in Tephra Caves, you’re immediately struck by the expansiveness of Gaur plain as it stretches beyond the horizon. The game is telling you that, from now on, you’re out of the introduction and free to go your own way (to a degree).&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/tk1zdGC.gif&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;Walking onto Gaur plan.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/RQrDjVw.jpg&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;Colony 9. Notice the clear walls on the other side, clearly indicating the limits of exploration.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;As we progress through the main quest, we are initially guided to a buggy in the middle of the plain, then a small oasis on its other side, then teleported back to the buggy, before then going to a refugee camp at the end of the plain (this route is mapped below). This continuous ping-ponging explicitly encourages the player to take different routes and explore the map a bit as they wander to the next checkpoint: through the use of various explicit mechanics (which we will get to soon), you’re encouraged to take detours on this already very winding path, and if you want to take the most direct route, you’ll still end up taking different paths throughout the plain, marked in blue below. Along the way, we meet Juju and Sharla, two siblings from Colony 6 (another colony of humans, or ‘homs’, further up the leg of the Bionis). After reaching the refugee camp, Sharla joins our party and Juju runs off to colony 6 to prove himself - leaving us to chase after him.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/W6mT7CV.png&quot; style=&quot;margin: 0 auto; width: 100%; background-color: black;&quot; /&gt;

&lt;figcaption&gt;1: Start of Gaur Plain; 2: Where you find the broken buggy; 3: The oasis; 4: The refugee camp. Dotted line indicates teleporting from the oasis back to the buggy.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/SSCkuRg.png&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;Juju and Sharla. Screenshot from the &lt;a href=&quot;https://xenoblade.fandom.com/wiki/Juju?file=XC1DE-Sharla-and-Juju.jpg&quot;&gt;&lt;i&gt;Xenoblade&lt;/i&gt; wiki&lt;/a&gt;.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Once we reach the refugee camp, we get the chance to stock up on items and accept some sidequests before progressing with the main quest. From the refugee camp, it’s a fairly straightforward path to Raguel bridge, taking us past some of the larger landmarks in the map, and over Raguel lake. All these landmarks are explorable, with various sidequests taking place in them. As such, some players will likely detour and explore the areas to complete sidequests (or just to check it out) before pressing forward with the game’s plot.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/OB1Ega7.png&quot; style=&quot;margin: 0 auto; width: 100%; background-color: black;&quot; /&gt;

&lt;figcaption&gt;4: refugee camp; 5: the start of Raguel bridge.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Once across the bridge, we go up to the upper segment of the map and fight the boss(es) of this area almost immediately! This upper segment is left almost completely unexplored and adds a little verticality to what is overall a fairly flat map. After beating the final boss and rescuing Juju, we’re teleported back to the refugee camp and told to go back to the upper segment to progress to the next area. After reaching and rescuing Juju from the bosses, the tension in main plotline is also at a low, giving us the perfect chance to dawdle, finish some sidequests, and explore before progressing to the next area (In fact, the initial sidequests in Bionis’ leg expire and cannot be completed once we complete the next chunk of the game).&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/GjyBR6C.png&quot; style=&quot;margin: 0 auto; width: 100%; background-color: black;&quot; /&gt;

&lt;figcaption&gt;5: start of Raguel bridge; 6: other side of Raguel bridge; 7: spiral mountain; 8: end of the map. Dotted line joins lower (left) and upper (right) halves of the map.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;So we can see that following the ‘critical’ path of the plot will not get us to explore anything near the majority of the leg, but the way we are moved across the map (including being teleported back to previous locations) implicitly encourages the player to take different routes and explore more of the map as they go. Furthermore, the small trek back across the map after finishing the main quest in this area gives us the perfect chance to explore and take a break from the story before moving on. As such, the main quest works as an ‘initial tour’ of the map - showing off the major landmarks, but not actually exploring them or entering the many nooks and crannies present across Bionis’ leg.&lt;/p&gt;

&lt;h2 id=&quot;chopping-up-the-leg-a-brief-note&quot;&gt;Chopping up the Leg: A brief note&lt;/h2&gt;

&lt;p&gt;So, having stepped through the story of this area, we can clearly see that the map has three major sections:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Gaur Plain and surroundings&lt;/li&gt;
  &lt;li&gt;Viliera Hill &amp;amp; Raguel Lake&lt;/li&gt;
  &lt;li&gt;Upper level and the caves below (where the holes in the upper level drop down into the caves)&lt;/li&gt;
&lt;/ol&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/yZLRrDh.png&quot; style=&quot;margin: 0 auto; width: 100%; background-color: black;&quot; /&gt;

&lt;figcaption&gt;The three areas, separated by red lines. Areas are organised left to right, following the above list. Upper area is the disjointed section on the right.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This results in a fairly clear ‘hub and spoke’ design: each section has some central vast area and then branches out into smaller areas and routes. One example of this is Daksha shrine, which is at the end of a small path off the side of Viliera hill. This path consists of a short climb to a shrine area, with a unique monster (think optional boss) at the end.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/7SHnI0t.jpg&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;A photo of Daksha shrine (the boss here is lying in wait just beyond the edge of the shrine).&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This ‘hub and spoke’ design is nothing new - &lt;em&gt;Mario 64&lt;/em&gt; is perhaps one of the most famous examples of such a design - but is nonetheless effective in allowing a mixture of open-world exploration (i.e. the flat plains) and tighter level design (e.g. tight cave systems, which force certain enemy encounters or even some light platforming). It’s also worth noting that the latter two areas (especially the final area) are not explored thoroughly during the main quest, meaning that they contain many more extra areas and secrets for sidequests and exploration. In addition, these areas are also far more geographically interesting than the flat Gaur plain, making them inherently more interesting to explore. So as we progress in the area, there are not only more areas to explore, but also more diversity in the geography of the areas themselves.&lt;/p&gt;

&lt;h2 id=&quot;sidequests&quot;&gt;Sidequests&lt;/h2&gt;

&lt;p&gt;Of course, the main quest is not the only thread we have to follow. Over the course of the game (including in Bionis’ leg), you’ll likely pick up various sidequests. These can range from generically-named collection quests (‘materials quest 1’) to small story quests, with fleshed out plotlines and lasting world effects (primarily expressed via an impressive relationship chart system that displays the relationship between the various characters you meet on your journey).&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/OlgJPDm.png&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;A full affinity chart from the game. Zoomed out to both show scale and hide the details of some of these relationships (which are spoiler-y). Center area normally reveals party members and areas, but here is hidden to avoid spoilers.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;These sidequests have a variety of benefits (experience, items, money), but more importantly, they also further encourage exploration in two key ways:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;They encourage players to take detours from the main quest: if you see an item or enemy a little way away while progressing the plot, you may as well go get it to fulfil a sidequest (it helps that these are marked on the map, so it’s hard to miss these while wandering around).&lt;/li&gt;
  &lt;li&gt;They encourage players to enter ‘spokes’/side areas in the world that otherwise are not relevant to the main quest.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first type of sidequest is fairly common: &lt;em&gt;Xenoblade&lt;/em&gt; is full of generic fetch quests that you can accept in bulk, and don’t require returning to the quest giver to finish. This encourages a gameplay style where you accept these quests in bulk and simply detour to pick up certain items or kill certain enemies when you come across them. These quests can be dull, but also seem to be designed more as something to idly do on the side rather than explicitly set out to finish.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/MvZPnb9.jpg&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;It's quite mean of those Tirkins to steal an old man's clothes!&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The second type of sidequest tends to be the more interesting one, often adding some backstory to the areas in the world, and filling out the relationships between various characters. For example, take the sidequest ‘thieving monsters’. In this sidequest, you’re asked to retrieve some refugees’ clothes, which had been stolen by a race of creatures called Tirkins while they were hanging to dry. This takes you to an area called Tirkin headquarters, where several Tirkins stand guard (including a unique Tirkin boss). You have to sneak around or fight these Tirkins (some of them likely being far too high-level for you at this point in the game, forcing you to sneak) in order to retrieve the clothes. So in taking this quest, we discover a new area (Tirkin headquarters), have to do a tiny bit of stealth, and discover new things about the relationship between Tirkins and homs (Tirkins seem to be somewhat intelligent, but are antagonistic to homs).&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/fkWIV3m.jpg&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;The Tirkins tend to attack you on site, especially when you're in their headquarters without permission.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In addition, sometimes these types of sidequests are chained together to tell a short story. For example, take the quest chain ‘The lost Nopon’, ‘With much gratitude’, and ‘With even more gratitude’ in Bionis’ Leg. The first quest involves you finding a small Nopon (one of the friendly races in the game) called Batubatu after he has gotten lost looking for ingredients for dinner. In the second quest, Batubatu wants to make someone (spoiler: it’s you!) a gift, so you have to find the ingredients for it. In the final quest, Batubatu gets lost looking for another present for you, and you have to find him and then the gift he was looking for. After all this, Batubatu promises to stop trying to get you gifts, and not to wander off again without telling his friend Gerugu (who gives two of these quests), finishing his little character arc. So, in following this chain, you learn about Batubatu and his relationship with Gerugu while exploring various parts of the map, including a secret area called Believer’s paradise (more on secret areas below). This quest chain thus fleshes out the world in a variety of ways simultaneously!&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/u0XAuO0.jpg&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;Gerugu asking for help finding Batubatu (again).&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/UflguaU.jpg&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;Batubatu doesn't seem to realise he's lost.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/EoTRWvm.jpg&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;Batubatu once again adventuring a bit further than is safe for him.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;So as we can see, sidequests further encourage exploration by both encouraging detours and encouraging the player to go down entirely separate routes. One of the largest weaknesses of &lt;em&gt;Xenoblade&lt;/em&gt; is actually that it does not significantly distinguish the two types of sidequests (and there are far more dull sidequests than interesting ones), but despite this, all these sidequests still work to encourage us to explore &lt;em&gt;Xenoblade&lt;/em&gt;’s world - both the land itself and the relationships and stories of the creatures that inhabit it.&lt;/p&gt;

&lt;h2 id=&quot;traversal-and-navigation-systems&quot;&gt;Traversal and Navigation systems&lt;/h2&gt;

&lt;p&gt;As a side note, let’s briefly talk about how you actually move in &lt;em&gt;Xenoblade&lt;/em&gt;. When exploring, you can run or walk on flat ground, and have a fairly floaty jump to allow for jumping over small obstacles, off cliff edges, or even (in some cases) off slides. While this is standard, the newly released definitive edition also includes an auto-run mechanic that allows you to simply set your character running in a single direction. This makes the large maps of &lt;em&gt;Xenoblade&lt;/em&gt; slightly less tedious - you can set your character off running towards your goal and check your phone or something while he gets there. More importantly to me, it frees up the camera: you can move the camera around your character while they run, further giving you the chance to spot interesting landmarks or other areas you’d like to explore. So, this addition works to make exploration easier: it frees the camera to allow the players to take in the environment around them as they move through it.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/GV324Zm.jpg&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;Shulk (the main character) struggling to run up a hill while I just admire the pretty sunset highlighting Mechonis.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In addition to the newly added auto-run, the game also has a minimap with the quickest path to whatever quest goal you currently have set. While useful, this does little to aid exploration beyond showing you where to go if you get lost en route to a quest. One potential positive benefit is that it allows the game world to be designed without worrying about players getting lost or confusing locations, but as I played the game with the mini-map on, I can’t talk about how it feels playing without it, although I’d be interested in finding out at some point!&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/mTo4chb.jpg&quot; style=&quot;margin: 0 auto;&quot; /&gt;

&lt;figcaption&gt;The minimap in the definitive edition.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;explicit-exploration-systems&quot;&gt;Explicit Exploration Systems&lt;/h2&gt;

&lt;p&gt;While following the checkpoints provided by quests and taking detours is a valid way to explore the world, &lt;em&gt;Xenoblade&lt;/em&gt; goes one step further in providing an explicit exploration system: as you find particular landmarks or reach particular areas, the game provides a pop-up of the area name, along with a large chunk of experience points (in fact, levelling up just from a decent amount of exploration is not uncommon in my experience).&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/2WL0KVY.png&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;Example of a landmark popup.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;There are three types of areas that give experience: landmarks (buildings/objects in the world), locations (general areas in the world), and secret areas. Secret areas get a special extra-fancy pop-up, as seen below, and are generally small areas that are harder to find. There are two of these in Bionis’ leg: Believer’s Paradise and the Observation Platform, both of which provide excellent views to take in. While Believer’s Paradise is part of a sidequest chain, as mentioned above, the Observation Platform is not, meaning that you will only discover it if you take the time to explore the map on your own volition.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/19qISgZ.jpg&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;Example of a secret area popup.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;As such, it’s clear that these secret areas (especially those that are not part of a sidequest) further encourage exploration, and often these areas reward the curious player with great views or an especially unique design (or both!).&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/uzxm3YH.jpg&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;The view from Believer's paradise.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;As a result, you as a player &lt;em&gt;are taught to enjoy exploring&lt;/em&gt; the more you play the game, and explicitly encouraged to try and go off the beaten path to find these secret areas. If you’re struggling with a boss or enemy and want to grind - no need to battle, just explore and gain experience that way, potentially discovering some really cool areas! Over time (especially since &lt;em&gt;Xenoblade&lt;/em&gt; is a very, very long game) this positive reinforcment will likely condition you to a degree to enjoy exploration for exploration’s sake (at least, it did for me).&lt;/p&gt;

&lt;p&gt;So this explicit system means that, beyond just having sidequests and a plot to follow, players are explicitly encouraged and taught to enjoy exploration in &lt;em&gt;Xenoblade&lt;/em&gt; and uncover as many of the nooks and crannies of the world as they can. As we as players do this, we get a greater sense of the scale and nature of the world of &lt;em&gt;Xenoblade&lt;/em&gt;, heightening our immersion and interest in the game. This system builds a stronger connection between progress and open-form exploration in a positive, but not overly checklist-y way.&lt;/p&gt;

&lt;h2 id=&quot;non-systemic-interactions&quot;&gt;Non-systemic Interactions&lt;/h2&gt;

&lt;p&gt;Having covered the systems that encourage us to explore, let’s look at the non-systemic elements of &lt;em&gt;Xenoblade&lt;/em&gt; that work to encourage and inspire exploration. These are generally more subjective elements of the game that work to make the world more interesting, whether that be through map design or enemy placement.&lt;/p&gt;

&lt;h2 id=&quot;skyboxes&quot;&gt;Skyboxes&lt;/h2&gt;

&lt;p&gt;One of the big selling points of &lt;em&gt;Xenoblade&lt;/em&gt; is the uniqueness of its world: a world built on two living creatures. Throughout the game, this is most obviously expressed through the skybox of various areas: for example, in Bionis’ Leg, we can see the Mechonis looming over us when we look back out across the world.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/QtHlks5.jpg&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;The view of Mechonis from Gaur plain.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This constant reminder of your place in the world, along with pop-ups denoting where you are on the Bionis when you reach a new map, encourages thinking about how your current area fits into the greater world of &lt;em&gt;Xenoblade&lt;/em&gt;, and potentially even exourages exploring to find areas that further give you unique views over the Bionis or the Mechonis. It also remainds you how insignificantly small you are in comparison to these god-like creatures, which ties into the themes of the game as a whole (you can play the game yourself if you want to find out how!).&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/qOjBGIt.jpg&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;The view of Mechonis from the entrance to Bionis' leg.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;world-design&quot;&gt;World Design&lt;/h2&gt;

&lt;p&gt;Another way to stoke curiosity is to create interesting and unique areas (easier said than done). There are a fair few interesting areas throughout Bionis’ leg, although the most unique and interesting are (in my opinion) left to later in the game. As you progress through the Leg, you’ll see Viliera hill, a skeletal-like set of platforms that jut out from the ground. As these are not far out of your way in the main quest, you might decide to wander up them to get a better look over the rest of the leg area. Alternatively, you might decide to explore the area visible beneath Raguel bridge - a lake with mushroom-like platforms jutting out from it - wondering what treasures or creatures could lie below. In fact, if you explore this area thoroughly, your curiosity will be rewarded with a path to a secret area,. Similarly, the presence of creature dens (such as Tirkin’s headquarters) or mysterious landmarks (such as the various old temples and tombs found later in the game) encourage the player to think about and build up their understanding of the history and layout of the world, being a form of environmental storytelling.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/c3POQM3.jpg&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;A view over Raguel lake.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;If you’re still wondering ‘but how nice can the game look, anyway?’, and you’re willing to be spoiled on the areas of &lt;em&gt;Xenoblade Chronicles&lt;/em&gt;, then I really recommend checking out Nintendo’s ‘&lt;em&gt;7 Minutes of Relaxation with Xenoblade Chronicles: Definitive Edition&lt;/em&gt;’ video, which showcases some of these areas with calm &lt;em&gt;Xenoblade&lt;/em&gt; music, and goes a bit of a way to showcase the unique and interesting designs of &lt;em&gt;Xenoblade’s&lt;/em&gt; world. Ultimately, it is the unique design of these areas that encourages exploration the most - the quests and systems surrounding exploration would not work nearly as well if they were accompanied by boring terrain. As such, these systems are not ways to force the player to spend more time with the game, but rather ways to encourage us soak in and think about the world of &lt;em&gt;Xenoblade&lt;/em&gt; as we wander through it.&lt;/p&gt;

&lt;iframe style=&quot;width: 100%; height: 400px&quot; src=&quot;https://www.youtube.com/embed/8HQjyHSe8iE&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h2 id=&quot;creatures-and-combat&quot;&gt;Creatures and combat&lt;/h2&gt;

&lt;p&gt;Of course, the world of &lt;em&gt;Xenoblade&lt;/em&gt; is filled with creatures (some of whom will attack on sight, and others who will simply roam peacefully until you attack). These creatures are largely placed in environmentally-consistent ways: the cow-like Armus are on the plain, the Tirkins are in their headquarters (and roam nearby areas in squads), the spider-like Arachnos dwell in the Windy Cave, and so on. These creatures sometimes roughly match your level, but certain areas contain enemies well above your level at the point in the story you can first see them. For example, the Windy Cave contains many enemies well above level 70, which players will usually only reach towards the end of the entire game. This not only encourages both some sneaking (if you really want to explore an area or finish a quest blocked by extremely strong enemies) and coming back to areas after further play -there may be extra areas or landmarks you’ve missed due to the high-level enemies blocking your progress.&lt;/p&gt;

&lt;p&gt;This all adds to the immersion: enemies are not magically at levels that perfectly match yours, but rather a whole assortment of levels that match their place in the ecosystem (e.g. the tougher enemies are usually the more predatory ones, such as the arachnos), and they are generally placed in locations that intuitively make sense, and build up your mental picture of the ecosystem of Bionis. In addition, smart placement works to pique to the player’s curiosity: why are Tirkins guarding that cave? What could be behind that Gogol? If you’re especially curious, you might decide to investigate then and there, potentially revealing a hidden path or area!&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/L3lTOcm.jpg&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;What could these Tirkins be guarding? (hint, it's an area pictured above!)&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/PVSg1BZ.jpg&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;What's behind this Gogol?&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;So, we’ve seen that getting players to explore your world relies a lot of things, most of which you’d expect: you want interesting maps and views, you want quests that take you around the map, and you want to make lots of extra interesting small areas that reward curious players. Additionally, with systems like secret areas and exploration experience, you can actually teach players to enjoy exploration, even if they weren’t necessarily inclined to do so before! This isn’t to say &lt;em&gt;Xenoblade&lt;/em&gt; is a perfect game, or even a perfect world: there are many boring quests and boring, tedious areas in the game. However, I think it’s still worth sitting back and appreciating the amount of work and thought that’s gone into the world, and into helping the player enjoy it as much as possible. The Bionis and the Mechonis have come a long way since they were just &lt;a href=&quot;http://iwataasks.nintendo.com/interviews/#/wii/xenoblade/1/0&quot;&gt;a diorama dreamt up during an idle train ride&lt;/a&gt;!&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/nODMqHg.png&quot; style=&quot;margin: 0 auto;&quot; /&gt;

&lt;figcaption&gt;The dioramas made by MonolithSoft when first coming up with &lt;i&gt;Xenoblade Chronicles&lt;/i&gt;.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Thanks for reading! I hope you enjoyed my first major attempt at writing something about a video game (and if I’ve made a mistake somewhere, sorry!). My blog is usually full of technical posts (and has largely been left absent over the past year - thanks 2020), but I’m hoping this year to add some more non-technical writing, whether that be essay-style pieces like this one, some translations and disscussions, or whatever else happens to float through my brain. I’m aiming to put something out every month or two, depending on my own schedule. If you want a more technical post, I just posted a piece on stack neural module networks alongside this one, so &lt;a href=&quot;/2021/01/31/snmn&quot;&gt;go check it out&lt;/a&gt;! Next time, I’ll be taking a look at the work of Heron of Alexandria, a pretty well-known and interesting Roman inventor.&lt;/p&gt;</content><author><name></name></author><category term="blog" /><category term="non-technical" /><summary type="html">As our world seemingly fell apart around us in 2020, I found comfort in exploring a virtual one: the world of Xenoblade Chronicles. This world is a living one: the creatures of Xenoblade live on the arms, shoulders, and every other part of two massive creatures called the Bionis and the Mechonis, smaller creatures living quite literally on the backs of these god-like humanoid giants.</summary></entry><entry><title type="html">Stack Neural Module Networks</title><link href="https://hamishivi.github.io/2021/01/31/snmn.html" rel="alternate" type="text/html" title="Stack Neural Module Networks" /><published>2021-01-31T00:00:00+00:00</published><updated>2021-01-31T00:00:00+00:00</updated><id>https://hamishivi.github.io/2021/01/31/snmn</id><content type="html" xml:base="https://hamishivi.github.io/2021/01/31/snmn.html">&lt;blockquote&gt;
  &lt;p&gt;❗️ tl;dr: I implemented a &lt;a href=&quot;https://arxiv.org/pdf/1807.08556.pdf&quot;&gt;stack neural module network&lt;/a&gt; in PyTorch. You can see the code &lt;a href=&quot;https://github.com/hamishivi/snmn-pytorch&quot;&gt;here&lt;/a&gt; and a visualisation/demo of the network &lt;a href=&quot;https://snmn-pytorch.herokuapp.com/&quot;&gt;here&lt;/a&gt;!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Recently I’ve been quite interested in the notion of &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/pdf/1511.02799.pdf&quot;&gt;neural module networks&lt;/a&gt;  (NMNs)&lt;/strong&gt; - neural networks that operate by first parsing a question into a program, and then executing that program using a set of neural modules. Ideally, this approach allows us to take a multi-task learning approach without specifying the tasks - rather, during training the network learns to use the different modules for specific sub-tasks on its own.&lt;/p&gt;

&lt;!--more--&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/NIuxUSz.png&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;Example of NMN applied to visual question answering. The network answers the question 'where is the dog' by parsing the question into a module layout, passing the image and text through the modules, before combining the final output with the question to predict the answer. Image from original NMN paper.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1704.05526.pdf&quot;&gt;There&lt;/a&gt; &lt;a href=&quot;https://openreview.net/pdf?id=SygWvAVFPr&quot;&gt;have&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/pdf/1807.08556.pdf&quot;&gt;been&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/pdf/1909.05803.pdf&quot;&gt;several&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/pdf/1601.01705.pdf&quot;&gt;improvements&lt;/a&gt; made to NMNs since they were first proposed in 2015, so I wanted to get some hands-on experience by re-implementing an existing recent paper that extends NMNs. Inspired by some work applying &lt;a href=&quot;https://arxiv.org/pdf/1807.08556.pdf&quot;&gt;stack neural module networks&lt;/a&gt; to a task I’ve been working on for my own research, I decided that the original stack neural module network (SNMN) would be a good candidate for re-implementation. The &lt;a href=&quot;https://github.com/ronghanghu/snmn&quot;&gt;original repository&lt;/a&gt; was written in TensorFlow, so I decided to re-write it into PyTorch and make a little demo visualisation. Check the tl;dr box above for the links - or stay for a little description of how the SNMN works!&lt;/p&gt;

&lt;h2 id=&quot;so-how-does-the-stack-neural-module-network-work&quot;&gt;So how does the stack neural module network work?&lt;/h2&gt;

&lt;p&gt;Well, the high-level description is pretty simple: we give the network a question and an image. We then parse the question into a list of modules to execute and pass the image through a convolutional network to get high-level features. We then execute each module as given by the parser, where all modules have access to a shared memory stack that they can push to and pop from. By averaging module outputs based on their probabilities, we can make the network differentiable and thus trainable using stochastic gradient descent (or rather, &lt;a href=&quot;https://arxiv.org/pdf/1412.6980.pdf&quot;&gt;Adam&lt;/a&gt;), which we use to train the SNMN!&lt;/p&gt;

&lt;p&gt;So let’s break this down a bit further. We can split the network into four key parts: the image processor, question parser, module network, and output unit.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;❓ &lt;strong&gt;A brief note on datasets&lt;/strong&gt;: The original SNMN paper examines two datasets: &lt;a href=&quot;https://cs.stanford.edu/people/jcjohns/clevr/&quot;&gt;CLEVR&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/pdf/1807.08556.pdf&quot;&gt;CLEVR-ref&lt;/a&gt; (created by the authors for the SNMN paper). Both are visual question answering (VQA) datasets, where the model is fed in a question and image and must predict an answer. For the CLEVR dataset, answers are chosen from a (long-ish) list of potential answers. For the CLEVR-ref dataset, answers are generated as bounding box coordinates around the object in the image that answers the question (where ‘questions’ are simply expressions pointing to objects in the image, and the answer is a bounding box around the objects).  The images in both datasets are simple computer-generated images of various simple 3d shapes. The questions are designed to test compositional reasoning abilities (i.e. how well the model can break down long complex questions and solve them step-by-step).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/wpG97Vu.png&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;Overview of the SNMN architecture from the original SNMN paper. We call the text encoder and layout controller together the question parser.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;image-encoder&quot;&gt;Image Encoder&lt;/h3&gt;

&lt;p&gt;This is fairly simple: we preprocess the input image by passing it through a pretrained image classification network and using the output from an intermediate layer as a high-level representation of the image, both compressing the image size and allowing our network to make use of the powerful features learnt by a generic image classifier. For the SNMN, we use a &lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;ResNet&lt;/a&gt; classifier and extract the output from the ‘conv4’ block. The classifier isn’t further trained during training, but we do further pass the features through a two-layer convolutional network to tune the features for best use with the rest of the network.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/Fg7J8bI.png&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;A ResNet with 34 layers. Diagram from &lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;the original paper&lt;/a&gt;.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;So after this step, we have nice image features we can use as inputs into our modules.&lt;/p&gt;

&lt;h3 id=&quot;question-parser&quot;&gt;Question Parser&lt;/h3&gt;

&lt;p&gt;This step is a bit more complex. We pass our network through a control unit, which is a recurrent unit that at each step outputs a probability distribution over the modules and a control state that summarises the current state of the question-answering process. This control state can be used as input to modules to allow interactions between the question and the image features.&lt;/p&gt;

&lt;p&gt;For the parser, we first need to encode our text. We do this by using a word embedding layer initialised randomly (since the CLEVR dataset has a small vocabulary, we don’t need pretrained word embeddings). This is then passed through a bidirectional LSTM to construct contextualised representations of each token in the question, \(\{h_1, h_2, ..., h_S\}\) (assuming there are \(S\) tokens in the question). The final states of the two LSTM directions are also concatenated to make a vector representation of the question as a whole, \(q\). We then run the control unit for a set number of time steps (default 10). At each timestep \(t\), the control unit performs the following:&lt;/p&gt;

\[\begin{aligned} 
u &amp;amp; = W_2 [ W_1^{(t)} q + b_1 ; c_{t-1}] + b_2 \\
w^{(t)} &amp;amp;= \text{softmax}(\text{MLP}(u)) \\
cv_{t,s} &amp;amp;= \text{softmax}(W_3(u \odot h_s)\\
c_t &amp;amp;= \sum_{s=1}^{S} cv_{t,s} \cdot h_s
\end{aligned}\]

&lt;p&gt;Here, \(W\) and \(b\) indicate weights and biases (trainable parameters). First, we combine the previous control state (the first control state being a learnt parameter) with a timestep-specific projection of the question to produce \(u\). An MLP is then used to work out the probability distribution of modules at this timestep \(w^{(t)}\). We then use \(u\) to calculate an attention distribution over the question words \(h_s\), determining which elements of the question are relevant at this point in time. This is then used to construct an attention-weighted summary vector of the question to be used as the current control state \(c_t\).&lt;/p&gt;

&lt;p&gt;Thus, from this we get a sense of the likelihood of using each module at each timestep - we’ll see how we use this later. We also get the control vector, which ‘tells’ modules what to look at.&lt;/p&gt;

&lt;h3 id=&quot;module-network&quot;&gt;Module Network&lt;/h3&gt;

&lt;p&gt;This is the core of the network, and has two key elements: the modules and the stack. The stack is a simple stack data structure. We store a stack pointer, and can push and pop elements from the stack, updating the pointer accordingly. The modules are defined as follows:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Module Name&lt;/th&gt;
      &lt;th&gt;Input&lt;/th&gt;
      &lt;th&gt;Output&lt;/th&gt;
      &lt;th&gt;Implementation&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Find&lt;/td&gt;
      &lt;td&gt;&lt;em&gt;none&lt;/em&gt;&lt;/td&gt;
      &lt;td&gt;attention map&lt;/td&gt;
      &lt;td&gt;\(a_{out} = conv_2 (conv_1(x) \odot Wc)\)&lt;/td&gt;
      &lt;td&gt;Looks at new image regions based on control state.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Transform&lt;/td&gt;
      &lt;td&gt;\(a\)&lt;/td&gt;
      &lt;td&gt;attention map&lt;/td&gt;
      &lt;td&gt;\(a_{out} = conv_2 (conv_1(x) \odot\\\quad\quad W_1 \sum (a \odot x) \odot W_2c)\)&lt;/td&gt;
      &lt;td&gt;Shifts image attention to somewhere new, conditioned on previous output.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;And&lt;/td&gt;
      &lt;td&gt;\(a_1\), \(a_2\)&lt;/td&gt;
      &lt;td&gt;attention map&lt;/td&gt;
      &lt;td&gt;\(a_{out} = \text{minimum}(a_1, a_2)\)&lt;/td&gt;
      &lt;td&gt;Returns intersection of two previous outputs.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Or&lt;/td&gt;
      &lt;td&gt;\(a_1\), \(a_2\)&lt;/td&gt;
      &lt;td&gt;attention map&lt;/td&gt;
      &lt;td&gt;\(a_{out} = \text{maximum}(a_1, a_2)\)&lt;/td&gt;
      &lt;td&gt;Returns union of two previous outputs.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Filter&lt;/td&gt;
      &lt;td&gt;\(a\)&lt;/td&gt;
      &lt;td&gt;attention map&lt;/td&gt;
      &lt;td&gt;\(a_{out} = \text{And}(a, \text{Find}())\)&lt;/td&gt;
      &lt;td&gt;Tries to select out regions from previously examined region.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Scene&lt;/td&gt;
      &lt;td&gt;&lt;em&gt;none&lt;/em&gt;&lt;/td&gt;
      &lt;td&gt;attention map&lt;/td&gt;
      &lt;td&gt;\(a_{out} = conv_1(x)\)&lt;/td&gt;
      &lt;td&gt;Tries to look at some objects in the image.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Answer&lt;/td&gt;
      &lt;td&gt;\(a\)&lt;/td&gt;
      &lt;td&gt;answer&lt;/td&gt;
      &lt;td&gt;\(y = W^T_1 (W_2 \sum (a \odot x) \odot W_3c)\)&lt;/td&gt;
      &lt;td&gt;Predicts answer for VQA task using previous output.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Compare&lt;/td&gt;
      &lt;td&gt;\(a_1\), \(a_2\)&lt;/td&gt;
      &lt;td&gt;answer&lt;/td&gt;
      &lt;td&gt;\(y = W^T_1 (W_2 \sum (a_1 \odot x) \odot \\ \quad\quad W_3 \sum (a_2 \odot x) \odot W_4c)\)&lt;/td&gt;
      &lt;td&gt;Predicts answer for VQA task using two previous outputs.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;NoOp&lt;/td&gt;
      &lt;td&gt;&lt;em&gt;none&lt;/em&gt;&lt;/td&gt;
      &lt;td&gt;&lt;em&gt;none&lt;/em&gt;&lt;/td&gt;
      &lt;td&gt;&lt;em&gt;does nothing&lt;/em&gt;&lt;/td&gt;
      &lt;td&gt;Does nothing. Allows model to ‘skip’ timesteps it does not need to use.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;As we can see, each module (apart from No-op) has either some input or output, popping from or pushing to the stack respectively. Different modules perform different tasks, and one of the interesting things about NMNs is that we can theoretically design new modules for new tasks without drastically changing the overall approach (e.g. for question answering), or potentially even learn modules during training.&lt;/p&gt;

&lt;p&gt;So how are these modules used? Well, we use the probability distribution from the control unit. At each timestep, we feed our current stack into each module (i.e. pop the required items from the stack and use them as inputs for the module) and weight the module outputs by the probability of using that module as predicted by the control unit. We then also sharpen the stack pointer using either softmax or hard argmax &lt;a href=&quot;https://github.com/ronghanghu/snmn/issues/3&quot;&gt;(apparently this choice makes little difference to the final performance of the model)&lt;/a&gt;. We do this for all modules apart from the answer and compare modules, which are used for generating answers to the input question. Both modules output an answer vector, which is concatenated with the previous answer vector and question and passed through a linear layer. The final output answer vector is a weighted average of these answer vector outputs from the final timestep (weighted by the probability from the control unit).&lt;/p&gt;

&lt;p&gt;Thus, after running \(T\) timesteps, we have a final stack, stack pointer, and memory vector. We pop the current top of the stack (i.e. the last attention map stored in memory), and output this and the memory vector, and pass this to the output unit to predict our final answer.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/4knmU0T.png&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;Example of a set of modules chosen by the SNMN, with visualisations. Diagram from the &lt;a href=&quot;https://arxiv.org/pdf/1807.08556.pdf&quot;&gt;SNMN paper&lt;/a&gt;.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;output-unit&quot;&gt;Output unit&lt;/h3&gt;

&lt;p&gt;This is fairly simple. For the VQA task, we simply take the memory vector and use a two-layer MLP to predict probabilities over the answer vocabulary (since CLEVR has a set list of answers). For CLEVR-ref, we take the attention map output, apply it to the image features to get the attended image features, and then use a linear layer to predict bounding box coordinates for the answer.&lt;/p&gt;

&lt;h2 id=&quot;training&quot;&gt;Training&lt;/h2&gt;

&lt;p&gt;One of the nice things about this setup is we can train on specific module layouts or not, depending on if we have annotations on which modules to use (‘ground truth layout annotations’) or not - simply apply a cross-entropy loss to the control unit module probabilities and add it to our overall loss. Otherwise, we can still train end-to-end just on questions and answers, and still get good performance (albeit with some variance in performance). This means the network is quite flexible and can make good use of extra annotations that help in determining layouts!&lt;/p&gt;

&lt;p&gt;When we compare the modules chosen by a model trained on ground truth layouts, I’ve found that the model trained with ground truth layout produces module layouts that are far more intuitive (and match human intuition far better) than the non-ground truth trained model, as makes sense. Sometimes the non-ground truth model’s choices can be quite weird, potentially indicating it’s using the modules in ways that don’t match their name and intedned use! &lt;a href=&quot;https://snmn-pytorch.herokuapp.com/&quot;&gt;Check out my demo&lt;/a&gt; if you want to check this out yourself.&lt;/p&gt;

&lt;p&gt;Overall, the network performs quite well, achieving over 90% accuracy in the QA tasks we test on. My re-implementation performs somewhat lower, but still close, to the results reported in the original paper - you can check out &lt;a href=&quot;https://github.com/hamishivi/snmn-pytorch&quot;&gt;the project repository&lt;/a&gt; for a table of results compared to the original paper results. The ‘scratch’ runs don’t work as well, suggesting my re-implementation struggles a bit with finding good layouts. This also is marked as difficult for the model to learn in the original implementation (they report best performance over four runs because of this). However, the runs with ground truth layouts still perform quite close to the original implementation.&lt;/p&gt;

&lt;h2 id=&quot;interpretability&quot;&gt;Interpretability&lt;/h2&gt;

&lt;p&gt;One of the interesting benefits of this modular approach is interpretability. Since the model tends to learn a peaky module probability distribution (even without module supervision), it effectively uses one module at a time! So we can examine what is going on by simply visualising which modules are chosen at each timestep, visualise what part of the question gets most heavily weighted at that timestep, and then also visualise the attention map pushed onto the stack by that module (apart from the answer-output modules, which don’t output attention maps).&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/v99wIk0.png&quot; style=&quot;margin: 0 auto; width: 100%&quot; /&gt;

&lt;figcaption&gt;Example probability distribution over modules from an SNMN trained without ground-truth layouts. Notice that it is almost entirely clustered at the 'transform' module.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In fact, I have done exactly this &lt;a href=&quot;https://snmn-pytorch.herokuapp.com/&quot;&gt;at this site&lt;/a&gt;, as a demo for my re-implementation! You can pick from a model trained with or without module layout supervision. Play around and see what happens if you’re interested! It’s pretty cool to have a network like this that shows you a degree of its ‘inner workings’, in my opinion. It’s made with &lt;a href=&quot;https://fastapi.tiangolo.com/&quot;&gt;FastAPI&lt;/a&gt; and &lt;a href=&quot;https://dashboard.heroku.com/&quot;&gt;Heroku&lt;/a&gt; (check out the repository to see how the site works) it’s nothing fancy. Note that the website uses free Heroku hosting, so it may take some time to startup and do its first inference as it downloads models and such.&lt;/p&gt;

&lt;p&gt;However, don’t get too carried away: the interpretability of neural module networks is a bit questionable. Why should the different modules behave exactly as we want them to, when we don’t explicitly supervise them? &lt;a href=&quot;https://arxiv.org/pdf/2005.00724.pdf&quot;&gt;It turns out sometimes neural modules aren’t quite as faithful to our descriptions as they might seem&lt;/a&gt;, and working to fix this is an active and recent area of research. I actually observed this in this repository - enforcing module validation (i.e. ensuring that modules could only be used if there was enough in the stack) during training resulted in the network re-using the find module exclusively, suggesting the network was simply trying to use the convolutional layer in that module for all sorts of tasks apart from ‘finding’.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Thanks for reading! It’s been a long time since I last posted on my blog - 2020 was a hell of a year, as it was for just about everyone. I hope you managed to learn something from this, or at least found it interesting! If you like my writing, please stick around - I’m planning to put out a bit more on my blog this year (around one post every month or two). Each post will come in pairs - a technical and a non-technical post. If things go to plan, each post will also come with a fun demo to play with! Next time, I’ll be looking at making a reinforcement learning-based pokemon player. Hope to see you then!&lt;/p&gt;

&lt;h3 id=&quot;bibliography&quot;&gt;Bibliography&lt;/h3&gt;

&lt;p&gt;I’ve linked directly to papers where possible, but here are all the papers I’ve referenced in a bibliography format:&lt;/p&gt;

&lt;p&gt;J. Andreas, M. Rohrbach, T. Darrell, and D. Klein.2016. &lt;a href=&quot;https://doi.org/10.1109/CVPR.2016.12&quot;&gt;Neural module networks&lt;/a&gt;. In &lt;em&gt;2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)&lt;/em&gt;, pages 39-48.&lt;/p&gt;

&lt;p&gt;Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein. 2016. &lt;a href=&quot;https://doi.org/10.18653/v1/N16-1181&quot;&gt;Learning to compose neural networks for question answering&lt;/a&gt;. In &lt;em&gt;Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies&lt;/em&gt;, pages 1545-1554, San Diego, California. Association for Computational Linguistics.&lt;/p&gt;

&lt;p&gt;Nitish Gupta, Kevin Lin, Dan Roth, Sameer Singh, and Matt Gardner. 2020. &lt;a href=&quot;https://openreview.net/pdf?id=SygWvAVFPr&quot;&gt;Neural module networks for reasoning over text&lt;/a&gt;. In &lt;em&gt;International Conference on Learning Representations (ICLR)&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;K. He, X. Zhang, S. Ren, and J. Sun. 2016. &lt;a href=&quot;https://doi.org/10.1109/CVPR.2016.90&quot;&gt;Deep residual learning for image recognition&lt;/a&gt;. In &lt;em&gt;2016 IEEE conference on Computer Vision and Pattern Recognition (CVPR)&lt;/em&gt;, pages 770-778.&lt;/p&gt;

&lt;p&gt;Ronghang Hu, Jacob Andreas, Trevor Darrell, and Kate Saenko. 2018. &lt;a href=&quot;https://arxiv.org/pdf/1807.08556.pdf&quot;&gt;Explainable neural computation via stack neural module networks&lt;/a&gt;. In &lt;em&gt;Proceedings of the European Conference on Computer Vision (ECCV)&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Ronghang Hu, Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Kate Saenko. 2017. &lt;a href=&quot;https://arxiv.org/pdf/1704.05526.pdf&quot;&gt;Learning to reason: End-to-end module networks for visual question answering&lt;/a&gt;. In &lt;em&gt;Proceedings of the IEEE International Conference on Computer Vision (ICCV)&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Yichen Jiang and Mohit Bansal. 2019. &lt;a href=&quot;https://doi.org/10.18653/v1/D19-1455&quot;&gt;Self-assembling modular networks for interpretable multi-hop reasoning&lt;/a&gt;. In &lt;em&gt;Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)&lt;/em&gt;, pages 4474-4484, Hong Kong, China. Association for Computational Linguistics.&lt;/p&gt;

&lt;p&gt;Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C Lawrence Zitnick, and Ross Girshick. 2017. &lt;a href=&quot;https://arxiv.org/pdf/1612.06890.pdf&quot;&gt;Clevr: A diagnostic dataset for compositional language and elementary visual reasoning&lt;/a&gt;. In &lt;em&gt;CVPR&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Diederik P. Kingma and Jimmy Ba. 2015. &lt;a href=&quot;http://arxiv.org/abs/1412.6980&quot;&gt;Adam: A method for stochastic optimization&lt;/a&gt;. In &lt;em&gt;3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Sanjay Subramanian, Ben Bogin, Nitish Gupta, Tomer Wolfson, Sameer Singh, Jonathan Berant, and Matt Gardner. 2020. &lt;a href=&quot;https://doi.org/10.18653/v1/2020.acl-main.495&quot;&gt;Obtaining faithful interpretations from compositional neural networks&lt;/a&gt;. In &lt;em&gt;Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics&lt;/em&gt;, pages 5594-5608, Online. Association for Computational Linguistics&lt;/p&gt;</content><author><name></name></author><category term="blog" /><category term="technical" /><summary type="html">❗️ tl;dr: I implemented a stack neural module network in PyTorch. You can see the code here and a visualisation/demo of the network here!</summary></entry><entry><title type="html">DenserFlow</title><link href="https://hamishivi.github.io/2019/09/27/denserflow.html" rel="alternate" type="text/html" title="DenserFlow" /><published>2019-09-27T00:00:00+00:00</published><updated>2019-09-27T00:00:00+00:00</updated><id>https://hamishivi.github.io/2019/09/27/denserflow</id><content type="html" xml:base="https://hamishivi.github.io/2019/09/27/denserflow.html">&lt;p&gt;This is just a little update post to link to my latest uni-project-turned-github-repo - I’m working on some more original work now, though it might take some time due to University classes starting and slowly taking over my free time.&lt;/p&gt;

&lt;p&gt;The project this time is DenserFlow, a very very very basic neural network library implemented just using Python and NumPy. This was part of a larger assignment, and I’m fairly happy with how it turned out. Check out the repository itself for examples of how it can be used. The code itself is well commented and documented (with autogenerated docs present in the repo!), meaning that it should be useful as a learning resource if you want to dig a little into how neural networks work behind the scenes! 😄&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/hamishivi/DenserFlow&quot;&gt;The repository can be found here&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><category term="blog" /><category term="technical" /><summary type="html">This is just a little update post to link to my latest uni-project-turned-github-repo - I’m working on some more original work now, though it might take some time due to University classes starting and slowly taking over my free time.</summary></entry><entry><title type="html">Minimax and Connect-Four</title><link href="https://hamishivi.github.io/2019/09/15/Connect-Four.html" rel="alternate" type="text/html" title="Minimax and Connect-Four" /><published>2019-09-15T00:00:00+00:00</published><updated>2019-09-15T00:00:00+00:00</updated><id>https://hamishivi.github.io/2019/09/15/Connect-Four</id><content type="html" xml:base="https://hamishivi.github.io/2019/09/15/Connect-Four.html">&lt;p&gt;Continuing with my streak of taking University projects and turning them into (slightly) more polished projects, I recently took an old connect 4 AI and made a website where you can play against it - you can have a go yourself &lt;a href=&quot;https://c4hamish.herokuapp.com&quot;&gt;here&lt;/a&gt; (due to Heroku hosting, it might take a second or two for the page to load). You can see the code itself &lt;a href=&quot;https://github.com/hamishivi/Connect4&quot;&gt;here&lt;/a&gt; - but if you’re interested, this post will step through the basic ideas behind how the AI works. I’m not doing anything super fancy, but the theory and code behind this simple AI are still pretty interesting!&lt;/p&gt;

&lt;h2 id=&quot;1-basic-minimax&quot;&gt;1. Basic Minimax&lt;/h2&gt;

&lt;p&gt;If you were to start training to be a pro chess player, the first thing you would practice would be prediction - trying to look ahead and see what moves your opponent will make, so you could then plan your own moves based on that. Traditional computer game AI works largely the same way - it tries to make predictions based on the current board, simulating moves and looking ahead to see which move will give it the best chance of winning. Of course, there are some big differences between human and AI players: AI players require the state of the game to be fed to them, disregarding potential hints in the other player’s behaviour, and AI players can compute future game states far faster and far more precisely than most humans. Looking at these two differences, it makes sense to leverage this computational power to remove any chance of loss - to simulate &lt;em&gt;every possible game&lt;/em&gt; from the current point in time. If at any given point of the game, you can see all possible moves, you should never lose (if the game is fair). This is the idea behind decision trees: simply construct a tree, branching at every move, and keep generating it until you have seen all possible ways the game can play out. This works well for games with few possible states, such as tic-tac-toe. Here’s an example of a small section of what such a decision tree might look like:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/bc17oZK.png&quot; alt=&quot;example tictactoe tree&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Even for a simple game like tic-tac-toe, we have lots of possible ways the game can go - each of the nines squares can contain either nothing, X, or O, so we have 19,683 (or 3^9) possible total states! &lt;a href=&quot;https://xkcd.com/832/&quot;&gt;If you’re clever, however, you can still represent this visually without it being too overwhelming.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, for a game like connect-four, we have an even larger board (usually 7 by 6), and although you can’t place tokens in any square, unlike tic-tac-toe, &lt;a href=&quot;https://oeis.org/A212693&quot;&gt;we still end up with an astonishing 4,531,985,219,092 possible game states&lt;/a&gt;. That’s 230,248,703 times more possible states than tic-tac-toe! (And connect-four isn’t even that complicated!)&lt;/p&gt;

&lt;p&gt;So, clearly, we need to speed things up - search as many of these states as we can within the smallest amount of time we can manage (ideally well below a second). One simple idea is to take the best option we have found after some point in time (i.e. a timeout). But this requires &lt;em&gt;weighting&lt;/em&gt; moves and states - having a method that allows us to concretely say “this state is worth &lt;em&gt;x&lt;/em&gt; points”. That is, we need a &lt;em&gt;value function&lt;/em&gt; - a way to score states. For win and loss states, where the game is finished, this is easy:  we can simply assign a nice big positive score to win states (say, 1000000), and a nice big negative score to loss states (say, -1000000). We also need a way to evaluate states that aren’t in a concrete win or lose position. You might want to do this by counting how many tokens you have in a row, or how many opportunities there are for making four-in-a-row. My system does precisely this: it first counts how many tokens you have in a row in each direction, and then checks to see if it is possible to convert these to four-in-a-row (since a three-in-a-row is useless when blocked!). My system also checks this for the opponent and then scores the board by subtracting the opponent’s score from my score (so, if the opponent has more opportunities to score, then the overall score should be negative, and vice-versa if I have more opportunities).&lt;/p&gt;

&lt;p&gt;Now we have a way to evaluate states, we could implement simple lookahead: simply look at the next set of possible moves, and then choose the highest score. But obviously, we want to generate as many states ahead as we can, in order to rely less on our imperfect scoring function. Hence, we need a way to ‘back-propagate’ values from possible future states into their predecessors, and eventually all the way back to the set of moves we can actually make in our next turn. We want to then maximise our potential score, and ideally minimise the opponent’s potential score as well (i.e. close off opportunities to them). The algorithm for doing this is called &lt;strong&gt;minimax&lt;/strong&gt;, since it &lt;em&gt;maximises&lt;/em&gt; the points that the player gets while &lt;em&gt;minimising&lt;/em&gt; the points of the opponent. Here’s a pseudocode description (adapted from &lt;a href=&quot;https://en.wikipedia.org/wiki/Minimax#Minimax_algorithm_with_alternate_moves&quot;&gt;Wikipedia&lt;/a&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-pseudocode&quot;&gt;function minimax(gameState, maximizingPlayer) is
    if state is a win/loss state then
        return the value of the state, using our value function
    if maximizingPlayer then
        value := −∞
        for each possible next game state of gameState do
            value := max(value, minimax(child, FALSE))
        return value
    else // minimizing player in this case
        value := +∞
        for each possible next game state of gameState do
            value := min(value, minimax(child, TRUE))
        return value
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can augment this with a depth limit, so you can only look ahead some number of moves (and so save computation time), or you could even update some global variable as you go down each turn, and then return whatever the AI’s “best guess” when your time runs out. This is very similar to the decision tree approach, with just some more formalisms about how to choose the best moves. Taking the previous tic-tac-toe example, we can visualise the algorithm like so (the board states are scored randomly, as opposed to being based on board state):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/EKAvHwE.png&quot; alt=&quot;example tictactoe tree&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In this diagram, the algorithm goes up to three turns rather than exploring the entire game. As we can see, we alternate between taking the &lt;em&gt;minimum&lt;/em&gt; of all possible scores (turns 3 to 2) and taking the &lt;em&gt;maximum&lt;/em&gt; of all possible scores (turns 2 to 1). Crucially, we also assume the opponent will make the best move available to them (hence we take the minimum score when simulating their turn, since high negative scores are worse for us but good for the opponent). Even if the opponent doesn’t make their best possible move, this algorithm will still give the best possible move we can make.&lt;/p&gt;

&lt;h1 id=&quot;2-alpha-beta-pruning&quot;&gt;2: Alpha-Beta Pruning&lt;/h1&gt;

&lt;p&gt;So far, the AI works really well! But we can still do better - there are far more optimisations we can apply. For example, game-specific optimisations can be made - for connect-four, we could order which columns we search first when placing tokens. In connect-four, searching the middle set of columns is better than searching the outer edges, since the middle set allows for more potential avenues to win - and this is exactly what my AI does!&lt;/p&gt;

&lt;p&gt;Another optimisation we can make is called &lt;a href=&quot;https://en.wikipedia.org/wiki/Alpha–beta_pruning&quot;&gt;‘alpha-beta pruning’&lt;/a&gt;. By being a bit cleverer about the minimax algorithm, we can drastically cut down on the number of moves we need to search. The idea behind alpha-beta pruning is simple: if we know a sub-tree we are searching won’t result in a better (or worse while minimising) move than we already have, we don’t bother fully exploring it. In the minimax algorithm, we assume that the opponent will play as well as we do - so, for example, if a move enables the opponent to win, we will assume that the opponent will always win when we make that move. Although they could make other moves, there is simply no point in exploring them since the opponent will always make that winning move if they are playing optimally (and even if they don’t play optimally, this still turns out to be the best move). This is precisely what alpha-beta pruning does, except it can calculate far more precisely what moves it shouldn’t search beyond. In fact, combining this with the optimisation on column search order we mentioned above helps even more, since more valuable moves will tend to be closer to the centre - so, this allows us to prune more branches and really speed up our AI.&lt;/p&gt;

&lt;p&gt;For example, taking our minimax example above, we &lt;strong&gt;wouldn’t&lt;/strong&gt; explore the final board on the right, since the current minimum score (0) from that right side of the tree is &lt;em&gt;lower&lt;/em&gt; than the score from the left side (1). Hence, no matter what other board states are left to explore in that subtree, we won’t find a move better than the one leading to the left subtree.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/6AyC8db.png&quot; alt=&quot;example tictactoe tree&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-going-a-bit-crazy&quot;&gt;3: Going (A) Bit Crazy&lt;/h1&gt;

&lt;p&gt;At this point, the AI is pretty good. Given enough time, it can never lose (if there is any way to win), and thanks to alpha-beta pruning, it’s pretty fast. But we can do better if we are clever about how we represent the game itself in code.&lt;/p&gt;

&lt;p&gt;Normally, you would represent a board with a simple two-dimensional array. This makes sense and is easy to use. A one-dimensional array will also do the trick, if you wanted. But, in the end, both these implementations will require iterations and similar things to check things such as valid moves, and count to see if anyone has made (or is close to) four-in-a-row yet. We can do definitely do better, by using a ‘bit-board’ - a representation of the board as a bit array. This allows us to operate on the board with bit-operations, which will prove to be more efficient than iteration in certain scenarios. If you want to know all sorts of fun bit-based algorithms, I really suggest checking out &lt;a href=&quot;https://graphics.stanford.edu/~seander/bithacks.html&quot;&gt;this bithacks page&lt;/a&gt;, which has all sorts of useful code snippets.&lt;/p&gt;

&lt;p&gt;To use a bit board, we have to maintain two boards - one for each player, since we can only express ‘1’ and ‘0’ in the board itself. You may also want to maintain a third board that just tracks where tokens are placed, but this can be created by bitwise ‘OR’ing the two boards together. While the bitboard is a simple one-dimensional bit array, it is useful to keep in mind how each bit maps to a board position:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/My2AfOs.png&quot; alt=&quot;bit number to connect-four position mapping&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The number bit is in the square it represents. The dotted squares are for the “scratch space” that doesn’t get used by the actual board, but is utilised by some of the algorithms below. This is not 100% representative of how the bit layout works in my code, but is very similar.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This bitboard allows us to do a lot of fun tricks! For example, my &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;is_win&lt;/code&gt; function, which checks if there is a four-in-a-row somewhere on the board:&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;is_win&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;uint64_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;board&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// vertical&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;uint64_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;board&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;board&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// horizontal&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;board&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;board&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// / diagonal&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;board&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;board&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// \ diagonal&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;board&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;board&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This looks quite scary (magic numbers oh boy), and is a bit tricky, but all four checks use roughly the same idea. Let’s run through how this works for the vertical columns first:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;First, we shift the bits in the board right by 1&lt;/li&gt;
  &lt;li&gt;We then bitwise ‘AND’ the board with the shifted board, and store this in ‘y’&lt;/li&gt;
  &lt;li&gt;We then shift the bits in ‘y’ right by 2, and bitwise ‘AND’ y with the shifted version of y&lt;/li&gt;
  &lt;li&gt;if there are any bits left that are ‘1’ after the previous step, the code will evaluate the condition as ‘true’ (in C++, only 0 is counted as false, which requires all bits to be ‘0’). This will only happen if there is a four-in-a-row vertically.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let’s now do these steps with this very basic example board:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/f0nLyX0.png&quot; alt=&quot;Red Tokens at bottom of bit board&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Lets now apply the above steps to this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/JjbAjcH.png&quot; alt=&quot;bit algorithm explanation image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note that the four-in-a-row that was vertical is &lt;em&gt;not&lt;/em&gt; picked up - the algorithm only works for one direction at a time!&lt;/p&gt;

&lt;p&gt;Each check in the other directions does a similar thing: we first shift by one to clear out tokens on their own, and tokens on the edge of rows. We then shift by two to clear out tokens in two-in-a-rows and three-in-a-rows, leaving only one set bit for each four-in-a-row that exists. The other directions essentially operate in the same way, but push the bits by the amount that it takes to shift all the bits in that specific direction by one. For example, shifting by eight is equivalent to shifting the bits up by one on the board, so that’s what we use for vertical checks.&lt;/p&gt;

&lt;p&gt;There’s another interesting bit-algorithm I used, and that’s determining the height that a token can be placed at during play. This is required to simulate moves, since you don’t want to consider illegal moves. Doing this manually is simple enough: find your column, and then just iterate up until you hit the first free square, and there you go! But with a bit-board, we can do something a bit more interesting:&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;uint64_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;board&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// all the verti bits flipped&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;uint64_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;board&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MAGIC_NUMBER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// clear all the set bits (=height next piece should be placed at)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cnt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// clear the least significant bit set&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The idea here is simple. First, we shift the board to the right by the column number we wish to inquire about. We then AND this with a magic number, which should correspond to the following board (red means that cell’s corresponding bit is set, as above - the precise number will depend on how you implement the bit board):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/kz0eSTi.png&quot; alt=&quot;bit height algorithm explanation image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Hence, by ANDing this board with the shifted columns, we isolate the column we want to check - if we want to check the first column, we shift by zero, and then AND it with the above board, resulting in a bitboard with only the bits corresponding to the first column set (if those bits had been set in the first place). For other columns, we simply shift that column to the position of the first column, and then AND it with the above board. Once this is done, we simply count the number of set bits from the bottom up to get the current height of that column. If the height equals the height of the board, we know the column is full. (Note that in my real code, the board layout is a bit different (essentially horizontally flipped), but I opted to keep things a bit simpler in this post. The bit tricks still work, except you use a right shift instead of a left one in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;get_height&lt;/code&gt; function).&lt;/p&gt;

&lt;h1 id=&quot;fin&quot;&gt;Fin&lt;/h1&gt;

&lt;p&gt;I hope this was an interesting and useful post, and thanks for reading! I had a bunch of fun writing this code up, especially messing around with the bitboard - I’d really recommend trying out bit-optimising your own code, if you have the time and energy! As a reminder, you can check out the code for the AI itself &lt;a href=&quot;https://github.com/hamishivi/Connect4/blob/master/ConnectFourTournament.cpp&quot;&gt;here&lt;/a&gt; if you’re interested. 😄&lt;/p&gt;</content><author><name></name></author><category term="blog" /><category term="technical" /><summary type="html">Continuing with my streak of taking University projects and turning them into (slightly) more polished projects, I recently took an old connect 4 AI and made a website where you can play against it - you can have a go yourself here (due to Heroku hosting, it might take a second or two for the page to load). You can see the code itself here - but if you’re interested, this post will step through the basic ideas behind how the AI works. I’m not doing anything super fancy, but the theory and code behind this simple AI are still pretty interesting!</summary></entry><entry><title type="html">Building a basic chatbot</title><link href="https://hamishivi.github.io/2019/07/26/chatbot.html" rel="alternate" type="text/html" title="Building a basic chatbot" /><published>2019-07-26T00:00:00+00:00</published><updated>2019-07-26T00:00:00+00:00</updated><id>https://hamishivi.github.io/2019/07/26/chatbot</id><content type="html" xml:base="https://hamishivi.github.io/2019/07/26/chatbot.html">&lt;p&gt;Over the course of my previous semester of University, I had the fun experience of building a small deep learning-based chatbot for a university assignment. It was really fun to see it working and get it running, so I figured it would also be great to clean it up and deploy it on the internet.&lt;/p&gt;

&lt;p&gt;You can check out the chatbot for yourself &lt;a href=&quot;https://microbotchat.heroku.com&quot;&gt;here&lt;/a&gt;! After initially visiting the site, wait a minute or two and try visiting it again - the chatbot takes about one or two minutes to start up (the tradeoff for having free hosting). Here’s an example of how it should work:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/fTGashO.gif&quot; style=&quot;margin: 0 auto;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The repository containing the code for the site can be found &lt;a href=&quot;https://github.com/hamishivi/microbot&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;basic-overview&quot;&gt;Basic Overview&lt;/h2&gt;

&lt;p&gt;The chatbot is quite simple, using a very simple encoder-decoder architecture (see below if you don’t know what that is). First, it takes in the user’s input, passing the words (as &lt;a href=&quot;https://en.wikipedia.org/wiki/Word_embedding&quot;&gt;word embeddings&lt;/a&gt;) into a layer of GRU units, which means it can take input of (more or less) arbitrary length. An attention mechanism is then applied to the output, determining which words in the input are most important for generating a response, and weighting the output values associated with each input word accordingly. Finally, this output and a ‘begin’ token are passed into another set of GRU units, which output a single number: the index of the best response in the list of possible responses. This is then used to look up and provide that chosen response. The image below summarises this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/W9bg3R7.png&quot; style=&quot;margin: 0 auto;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Since the model is simple, each input is treated individually - it has no memory of previous questions. This made deploying the model easy (as it requires no memory, it is essentially stateless) but means it can’t hold a very human-like conversation. In addition, as the model is choosing the best answer from a list of prewritten ones, the second you start asking questions that are unlike its training data, it will give very odd responses. Sometimes this can be fun, though! 😄&lt;/p&gt;

&lt;h2 id=&quot;training-data&quot;&gt;Training Data&lt;/h2&gt;

&lt;p&gt;The dataset used for training and looking up answers was the &lt;a href=&quot;https://github.com/microsoft/BotBuilder-PersonalityChat/tree/master/CSharp/Datasets&quot;&gt;Microsoft Personality Chat dataset&lt;/a&gt;, which is a fairly small dataset that comprises of common conversational patterns, mostly focussing on ‘chit-chat’. As part of the assignment, we used the ‘professional’, ‘friendly’, and ‘witty’ personality datasets (since the assignment more personalities have been added).&lt;/p&gt;

&lt;h2 id=&quot;encoder-decoder-architecture&quot;&gt;Encoder-Decoder Architecture&lt;/h2&gt;

&lt;p&gt;The encoder-decoder architecture is a common architecture used for neural network models in NLP (although, at time of writing, transformer architectures are quickly taking over the field). It consists of two basic units: the encoder and the decoder. The encoder’s job is to ‘encode’ the input - that is, to take in input and transform (or ‘encode’) it into a form useful for the task, while doing some analysis of the input. So it takes in two inputs: the previous state of the encoder (which allows it to retain the memory of previously happened in the input), and the current input (usually a word embedding). If it is the first word in the input, we just pass in all zeroes as the previous state. We thus feed in each word one by one, and at the final word get the output from the encoder and save it.&lt;/p&gt;

&lt;p&gt;The decoder then, well, ‘decodes’ this output. It takes two inputs: the previous state of the decoder (so the model can remember what it has already said) and the previous output from the decoder (e.g. the previous response output). However, rather than setting the previous state to all 0s for the first step, we set it to the output state from the encoder after the encoder had processed the input. This allows the decoder to then ‘decode’ this and generate an appropriate response.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/fit/c/1400/420/1*Ismhi-muID5ooWf3ZIQFFg.png&quot; style=&quot;margin: 0 auto;&quot; /&gt;&lt;/p&gt;
&lt;div style=&quot;text-align:center;&quot;&gt;&lt;i&gt;Credits to &lt;a href=&quot;https://towardsdatascience.com/sequence-to-sequence-model-introduction-and-concepts-44d9b41cd42d&quot;&gt;Towards Data Science&lt;/a&gt; for the above image.&lt;/i&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;There are more additions we can make on top of this basic structure: we can ‘stack’ encoders and decoders, essentially just adding more layers to them. We can also, say, use bidirectional encoders: two encoders which get fed the input in opposite directions, allowing them to track different aspects of the input. The output states are then combined in some way (e.g. just adding them together). More recently, there are also &lt;em&gt;attention mechanisms&lt;/em&gt; that can be applied. These mechanisms essentially take the output of the encoder at each step and weight it according to a given step’s importance to the decoder, modelling the idea of ‘attentiveness’. For example, the model (should) weight the encoder output for ‘name’ much more than any other word in the sentence ‘What’s your name?’, since it is the most crucial word for answering the question. If you’re interested, I recommend going out and reading up on the area, since NLP deep neural net architectures are currently a fast-moving and exciting space, in which a lot of new work is being done.&lt;/p&gt;

&lt;p&gt;For my model, I used bidirectional encoders with a basic attention mechanism, using 256 gated recurrent units (GRU) for the encoder and decoder. Hence, my encoder looked something like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/DtZcJw4.png&quot; style=&quot;margin: 0 auto;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;hosting&quot;&gt;Hosting&lt;/h2&gt;

&lt;p&gt;Hosting this model was somewhat tricky. A simple ‘drag and drop’ of my assignment code, unfortunately, did not work due to the RAM requirements of word embeddings - using Gensim, a set of trained word vectors would take up gigabytes of RAM - far more than the modest 512 MB a free Heroku dyno gives you, nevermind that the saved weights file itself was at least a gigabyte, if not more. So I needed to find a way to load word embeddings without having to load them all at once, and in the best case not even have to upload the saved weights with it - and I found exactly what I needed in &lt;a href=&quot;https://github.com/plasticityai/magnitude&quot;&gt;Magnitude&lt;/a&gt;. This library allows for remote streaming of pre-trained word embeddings, meaning that the word embeddings can be served from a file hosted by the library maintainers. It also supports partial loading of your own files, if you don’t want to use their pre-trained embeddings. While streaming the vectors slows the chatbot down on slow web connections (such as my own), when hosted (with a far better connection) it makes little difference, well worth the tradeoff and saving many, many gigabytes of RAM.&lt;/p&gt;

&lt;p&gt;The website is hosted on Heroku, running within a dockerised container - see &lt;a href=&quot;https://github.com/hamishivi/microbot&quot;&gt;the code itself&lt;/a&gt; for the Dockerfile.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;If you made it to the end of the post, thanks for reading - hopefully this post helps you with your own projects in some small way! 😄&lt;/p&gt;</content><author><name></name></author><category term="blog" /><category term="technical" /><summary type="html">Over the course of my previous semester of University, I had the fun experience of building a small deep learning-based chatbot for a university assignment. It was really fun to see it working and get it running, so I figured it would also be great to clean it up and deploy it on the internet.</summary></entry></feed>